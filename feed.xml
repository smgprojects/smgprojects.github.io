<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shawn Graham&#39;s Open Digital Humanities Notebook 2016-17</title>
    <description>An open history notebook forked from Jason Heppler</description>
    <link>http://smgprojects.github.io/</link>
    <atom:link href="http://smgprojects.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 23 Jun 2017 12:54:17 -0400</pubDate>
    <lastBuildDate>Fri, 23 Jun 2017 12:54:17 -0400</lastBuildDate>
    <generator>Jekyll v3.1.3</generator>
    
      <item>
        <title>using hugo academic to make shawngraham.github.io</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#location-of-the-draft-folder&quot; id=&quot;markdown-toc-location-of-the-draft-folder&quot;&gt;location of the draft folder&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#writing&quot; id=&quot;markdown-toc-writing&quot;&gt;writing:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#build--deploy&quot; id=&quot;markdown-toc-build--deploy&quot;&gt;build &amp;amp; deploy:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#create-a-publication&quot; id=&quot;markdown-toc-create-a-publication&quot;&gt;Create a publication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#post-an-article&quot; id=&quot;markdown-toc-post-an-article&quot;&gt;Post an article&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#create-a-project&quot; id=&quot;markdown-toc-create-a-project&quot;&gt;Create a project&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#create-a-talk&quot; id=&quot;markdown-toc-create-a-talk&quot;&gt;Create a talk&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#manage-node-index-pages&quot; id=&quot;markdown-toc-manage-node-index-pages&quot;&gt;Manage node index pages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#removing-content&quot; id=&quot;markdown-toc-removing-content&quot;&gt;Removing content&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#view-your-updated-site&quot; id=&quot;markdown-toc-view-your-updated-site&quot;&gt;View your updated site&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deploy-your-site&quot; id=&quot;markdown-toc-deploy-your-site&quot;&gt;Deploy your site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;location-of-the-draft-folder&quot;&gt;location of the draft folder&lt;/h2&gt;

&lt;p&gt;/Users/shawngraham/experiments/hugo/my_githubio_site&lt;/p&gt;

&lt;h2 id=&quot;writing&quot;&gt;writing:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;is done in the ‘content’ folder&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;build--deploy&quot;&gt;build &amp;amp; deploy:&lt;/h2&gt;

&lt;p&gt;(from the github.com/gcushen/hugo-academic)&lt;/p&gt;

&lt;h2 id=&quot;create-a-publication&quot;&gt;Create a publication&lt;/h2&gt;

&lt;p&gt;To create a new publication:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hugo new publication/my-paper-name.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the default variables at the top of &lt;code&gt;content/publication/my-paper-name.md&lt;/code&gt; to include the details of your publication. The &lt;code&gt;url_&lt;/code&gt; variables are used to generate links associated with your publication, such as for viewing PDFs of papers. Here is an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+++
abstract = &quot;An abstract...&quot;
authors = [&quot;First author&#39;s name&quot;, &quot;Second author&#39;s name&quot;]
date = &quot;2013-07-01&quot;
image = &quot;&quot;
image_preview = &quot;&quot;
math = false
publication = &quot;The publishing part of the citation goes here. You may use *Markdown* for italics etc.&quot;
title = &quot;A publication title, such as title of a paper&quot;
url_code = &quot;&quot;
url_dataset = &quot;&quot;
url_pdf = &quot;pdf/my-paper-name.pdf&quot;
url_project = &quot;&quot;
url_slides = &quot;&quot;
url_video = &quot;&quot;
+++

Further details on your publication can be written here using *Markdown* for formatting. This text will be displayed on the Publication Detail page.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;url_&lt;/code&gt; links can either point to local or web content. Associated local publication content, such as PDFs, may be copied to a &lt;code&gt;static/pdf/&lt;/code&gt; folder and referenced like &lt;code&gt;url_pdf = &quot;pdf/my-paper-name.pdf&quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can also associate custom link buttons with the publication by adding the following block(s) within the variable preamble above, which is denoted by &lt;code&gt;+++&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[url_custom]]
    name = &quot;Custom Link&quot;
    url = &quot;http://www.example.org&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you enabled &lt;code&gt;detailed_list&lt;/code&gt; for publications in &lt;code&gt;config.toml&lt;/code&gt;, then there are a few more optional variables that you can include in the publication page preamble. You may use &lt;code&gt;abstract_short = &quot;friendly summary of abstract&quot;&lt;/code&gt; and &lt;code&gt;publication_short = &quot;abbreviated publication details&quot;&lt;/code&gt; to display a friendly summary of the abstract and abbreviate the publication details, respectively. Furthermore, there is the option to display a different image on the homepage to the publication detail page by setting &lt;code&gt;image_preview = &quot;my-image.jpg&quot;&lt;/code&gt;. This can be useful if you wish to scale down the image for the homepage or simply if you just wish to show a different image for the preview.&lt;/p&gt;

&lt;p&gt;Any double quotes (&lt;code&gt;&quot;&lt;/code&gt;) or backslashes (e.g. LaTeX &lt;code&gt;\times&lt;/code&gt;) occurring within the value of any frontmatter parameter (such as the &lt;em&gt;abstract&lt;/em&gt;) should be escaped with a backslash (&lt;code&gt;\&lt;/code&gt;). For example, the symbol &lt;code&gt;&quot;&lt;/code&gt; and LaTeX text &lt;code&gt;\times&lt;/code&gt; become &lt;code&gt;\&quot;&lt;/code&gt; and &lt;code&gt;\\times&lt;/code&gt;, respectively. Refer to the &lt;a href=&quot;https://github.com/toml-lang/toml#user-content-string&quot;&gt;TOML documentation&lt;/a&gt; for more info.&lt;/p&gt;

&lt;h2 id=&quot;post-an-article&quot;&gt;Post an article&lt;/h2&gt;

&lt;p&gt;To create a blog/news article:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hugo new post/my-article-name.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the newly created file &lt;code&gt;content/post/my-article-name.md&lt;/code&gt; with your full title and content.&lt;/p&gt;

&lt;p&gt;Hugo will automatically generate summaries of posts that appear on the homepage. If you are dissatisfied with an automated summary, you can either limit the summary length by appropriately placing &lt;code&gt;&amp;#60;&amp;#33;&amp;#45;&amp;#45;more&amp;#45;&amp;#45;&amp;#62;&lt;/code&gt; in the article body, or completely override the automated summary by adding a &lt;code&gt;summary&lt;/code&gt; parameter to the &lt;code&gt;+++&lt;/code&gt; preamble such that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;summary = &quot;Summary of my post.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To disable commenting for a specific post, you can add &lt;code&gt;disable_comments = true&lt;/code&gt; to the post &lt;code&gt;+++&lt;/code&gt; preamble. Or to disable commenting for all posts, you can either set &lt;code&gt;disqusShortname = &quot;&quot;&lt;/code&gt; or &lt;code&gt;disable_comments = true&lt;/code&gt; in &lt;code&gt;config.toml&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;create-a-project&quot;&gt;Create a project&lt;/h2&gt;

&lt;p&gt;To create a project:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hugo new project/my-project-name.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the newly created file &lt;code&gt;content/project/my-project-name.md&lt;/code&gt;. Either you can link the project to an external project website by setting the &lt;code&gt;external_link = &quot;http://external-project.com&quot;&lt;/code&gt; variable at the top of the file, or you can add content (below the final &lt;code&gt;+++&lt;/code&gt;) in order to render a project page on your website.&lt;/p&gt;

&lt;h2 id=&quot;create-a-talk&quot;&gt;Create a talk&lt;/h2&gt;

&lt;p&gt;To create a talk:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hugo new talk/my-talk-name.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the newly created file &lt;code&gt;content/talk/my-talk-name.md&lt;/code&gt; with your full talk title and details. Note that many of the talk parameters are similar to the publication parameters.&lt;/p&gt;

&lt;h2 id=&quot;manage-node-index-pages&quot;&gt;Manage node index pages&lt;/h2&gt;

&lt;p&gt;The node index pages (e.g. &lt;code&gt;/post/&lt;/code&gt;) are the special pages which list all of your content. They can exist for blog posts, publications, and talks. The homepage widgets will automatically link to the node index pages when you have more items of content than can be displayed in the widget. Therefore, if you don’t have much content, you may not see the automatic links yet - but you can also manually link to them using a normal Markdown formatted link in your content.&lt;/p&gt;

&lt;p&gt;You can edit the title and add your own content, such as an introduction, by creating and editing the following content files for the node indexes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hugo new post/_index.md
hugo new publication/_index.md
hugo new talk/_index.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then remove all parameters except for &lt;code&gt;title&lt;/code&gt;, &lt;code&gt;math&lt;/code&gt;, &lt;code&gt;highlight&lt;/code&gt;, and &lt;code&gt;date&lt;/code&gt;. Edit the &lt;code&gt;title&lt;/code&gt; parameter as desired and add any content after the &lt;code&gt;+++&lt;/code&gt; preamble/frontmatter ends. For example, you should have something similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;+++
title = &quot;List of my posts&quot;
date = &quot;2017-01-01T00:00:00Z&quot;
math = false
highlight = false
+++

Below is an automatically generated list of all my blog posts!

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;removing-content&quot;&gt;Removing content&lt;/h2&gt;

&lt;p&gt;Generally, to remove content, simply delete the relevant file from your &lt;code&gt;content/post&lt;/code&gt;, &lt;code&gt;content/publication&lt;/code&gt;, &lt;code&gt;content/project&lt;/code&gt;, or &lt;code&gt;content/talk&lt;/code&gt; folder.&lt;/p&gt;

&lt;h2 id=&quot;view-your-updated-site&quot;&gt;View your updated site&lt;/h2&gt;

&lt;p&gt;After you have made changes to your site, you can view it by running the &lt;code&gt;hugo server --watch&lt;/code&gt; command and then opening &lt;a href=&quot;http://localhost:1313&quot;&gt;localhost:1313&lt;/a&gt; in your web browser.&lt;/p&gt;

&lt;h2 id=&quot;deploy-your-site&quot;&gt;Deploy your site&lt;/h2&gt;

&lt;p&gt;Finally, you can build the static website to a &lt;code&gt;public/&lt;/code&gt; folder ready for deployment using the &lt;code&gt;hugo&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;You may then deploy your site by copying the &lt;code&gt;public/&lt;/code&gt; directory (by FTP, SFTP, WebDAV, Rsync, git push, etc.) to your production web server.&lt;/p&gt;

&lt;p&gt;Note that running &lt;code&gt;hugo&lt;/code&gt; does not remove any previously generated files before building. Therefore, it’s best practice to delete your &lt;code&gt;public/&lt;/code&gt; directory prior to running &lt;code&gt;hugo&lt;/code&gt; to ensure no old or interim files are deployed to your server.&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 12:33:00 -0400</pubDate>
        <link>http://smgprojects.github.io/using-hugo-academic-to-make-shawngraham-dot-github-dot-io/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/using-hugo-academic-to-make-shawngraham-dot-github-dot-io/</guid>
        
        <category>writing</category>
        
        
        <category>Meta</category>
        
      </item>
    
      <item>
        <title>getting data out of opencontext</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#couple-of-ways-one-could-grab-it&quot; id=&quot;markdown-toc-couple-of-ways-one-could-grab-it&quot;&gt;COUPLE OF WAYS ONE COULD GRAB IT:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#congratulations&quot; id=&quot;markdown-toc-congratulations&quot;&gt;CONGRATULATIONS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#json&quot; id=&quot;markdown-toc-json&quot;&gt;json&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jqplay&quot; id=&quot;markdown-toc-jqplay&quot;&gt;JQPLAY&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#get-jq-and-run-the-query-from-the-terminal-or-command-line&quot; id=&quot;markdown-toc-get-jq-and-run-the-query-from-the-terminal-or-command-line&quot;&gt;GET JQ AND RUN THE QUERY FROM THE TERMINAL OR COMMAND LINE&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#combining-wget--jq&quot; id=&quot;markdown-toc-combining-wget--jq&quot;&gt;COMBINING WGET &amp;amp; JQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;a walkthrough for extracting and manipulating data from opencontext.org&lt;/p&gt;

&lt;p&gt;Search for something interesting. I put ‘poggio’ in the search box, and then clicked on the various options to get the architectural fragments. Look at the URL:
https://opencontext.org/subjects-search/?prop=oc-gen-cat-object&amp;amp;q=Poggio#15/43.1526/11.4090/19/any/Google-Satellite
See all that stuff after the word ‘Poggio’? That’s to generate the map view. We don’t need it.&lt;/p&gt;

&lt;p&gt;We’re going to ask for the search results w/o all of the website extras, no maps, no shiny interface. To do that, we take advantage of the API. With open context, if you have a search with a ‘?’ in the URL, you can put .json in front of the question mark, and delete all of the stuff from the # sign on, like so:&lt;/p&gt;

&lt;p&gt;https://opencontext.org/subjects-search/.json?prop=oc-gen-cat-object&amp;amp;q=Poggio&lt;/p&gt;

&lt;p&gt;Put that in the address bar. Boom! lots of stuff! But only one page’s worth, which isn’t lots of data. To get a lot more data, we have to add another parameter, the number of rows: ?rows=100&amp;amp;. Slot that in just before the p in prop= and see what happens.&lt;/p&gt;

&lt;p&gt;Now, that isn’t all of the records though. Remove the .json and see what happens when you click on the arrows to page through the NEXT 100 rows. You get a URL like this:&lt;/p&gt;

&lt;p&gt;https://opencontext.org/subjects-search/?rows=100&amp;amp;prop=oc-gen-cat-object&amp;amp;start=100&amp;amp;q=Poggio#15/43.1526/11.4090/19/any/Google-Satellite&lt;/p&gt;

&lt;p&gt;So – to recap, the URL is searching for 100 rows at a time, in the general object category, starting from row 100, and grabbing materials from Poggio. We now know enough about how open context’s api works to grab material.&lt;/p&gt;

&lt;h2 id=&quot;couple-of-ways-one-could-grab-it&quot;&gt;COUPLE OF WAYS ONE COULD GRAB IT:&lt;/h2&gt;
&lt;p&gt;You could copy n’ paste -&amp;gt; but that will only get you one page’s worth of data (and if you tried to put, say, 10791 into the ‘rows’ parameter, you’ll just get a time-out error). You’d have to go back to the search page, hit the ‘next’ button, reinsert the .json etc over and over again.
automatically. We’ll use a program called wget to do this. (To install wget on your machine, see the programming historian Wget will interact with the Open Context site to retrieve the data. We feed wget a file that contains all of the urls that we wish to grab, and it saves all of the data into a single file. So, open a new text file and paste our search URL in there like so:&lt;/p&gt;

&lt;p&gt;https://opencontext.org/subjects-search/.json?rows=100&amp;amp;prop=oc-gen-cat-object—oc-gen-cat-arch-element&amp;amp;q=Poggio
https://opencontext.org/subjects-search/.json?rows=100&amp;amp;prop=oc-gen-cat-object—oc-gen-cat-arch-element&amp;amp;start=100&amp;amp;q=Poggio
https://opencontext.org/subjects-search/.json?rows=100&amp;amp;prop=oc-gen-cat-object—oc-gen-cat-arch-element&amp;amp;start=200&amp;amp;q=Poggio&lt;/p&gt;

&lt;p&gt;…and so on until we’ve covered the full 4000 objects. Tedious? You bet. So we’ll get the computer to generate those URLS for us. Open a new text file, and copy the following in:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-#URL-Generator.py&quot;&gt;
urls = &#39;&#39;;
f=open(&#39;urls.txt&#39;,&#39;w&#39;)
for x in range(1, 4000, 100):
    urls = &#39;https://opencontext.org/subjects-search/.json?rows=100&amp;amp;prop=oc-gen-cat-object---oc-gen-cat-arch-element&amp;amp;start=%d&amp;amp;q=Poggio/\n&#39; % (x)
    f.write(urls)
f.close
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and save it as url-generator.py. This program is in the python language. If you’re on a Mac, it’s already installed. If you’re on a Windows machine, you’ll have to download and install it. To run the program, open your terminal (mac) or command prompt (windows) and make sure you’re in the same folder where you saved the program. Then type at the prompt:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;python url-generator.py&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This little program defines an empty container called ‘urls’; it then creates a new file called ‘urls.txt’; then we tell it to write the address of our search into the urls container. See the %d in there? The program writes a number between 1 and 4000; each time it does that, it counts by 100 so that the next time it goes through the loop, it adds a new address with the correct starting point! Then it saves that container of URLs into the file urls.txt. Go ahead, open it up, and you’ll see.&lt;/p&gt;

&lt;p&gt;Now we’ll feed it to wget like so. At the prompt in your terminal or command line, type:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget -i urls.txt -r --no-parent -nd –w 2 --limit-rate=10k&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You’ll end up with a lot of files that have no file extension in your folder, eg,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.json?rows=100&amp;amp;prop=oc-gen-cat-object---oc-gen-cat-arch-element&amp;amp;start=61&amp;amp;q=Poggio%2F&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Select all of these and rename them in your finder (instructions) or windows explorer (instructions), such that they have a sensible file name, and that the extension is .json. We are now going to concatenate these files into a single, properly formatted, .json file. (Note that it is possible for wget to push all of the downloaded information into a single json file, but it won’t be a properly formatted json file – it’ll just be a bunch of lumps of difference json hanging out together, which we don’t want).&lt;/p&gt;

&lt;p&gt;We are going to use a piece of software written for NodeJS to concatenate our json files (this enables us to develop in javascript; it’s useful for lots of other things too). Go to the NodeJS download page and download and install for your machine. (Windows users, make sure you select the npm package manager as well during the install procedure). Once it’s installed, open a terminal or command prompt and type&lt;/p&gt;

&lt;p&gt;&lt;code&gt;npm install -g json-concat (mac users, you might need sudo npm install -g json-concat)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This installs the json-concat tool. We’ll now join our files together:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# As simple as this. Output file should be last
$ json-concat file1.json file2.json file3.json file4.json ouput.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;… for however many json files you have.&lt;/p&gt;

&lt;h2 id=&quot;congratulations&quot;&gt;CONGRATULATIONS&lt;/h2&gt;
&lt;p&gt;You now have downloaded data from Open Context as json, and you’ve compiled that data into a single json file. This ability for data to be called and retrieved programmaticaly also enables things like the Open Context package for the R statistical software environment. If you’re feeling adventurous, take a look at that.&lt;/p&gt;

&lt;p&gt;In Part Two I’ll walk you through using JQ to masage the json into a csv file that can be explored in common spreadsheet software. (For a detailed lesson on JQ, see the programming historian, which also explains why json in the first place). Of course, lots of the more interesting data viz packages can deal with json itself, but more on that later.&lt;/p&gt;

&lt;p&gt;And of course, if you’re looking for some quick and dirty data export, Open Context has recently implemented a ‘cloud download’ button that will export a simplified version of the data direct to csv on your desktop. Look for a little cloud icon with a down arrow at the bottom of your search results page. Now, you might wonder why I didn’t mention that at the outset, but look at it this way: now you know how to get the complete data, and with this knowledge, you could even begin building far more complicated visualizations or websites. It was good for you, right? Right? Right.&lt;/p&gt;

&lt;p&gt;PS Eric adds: “Also, you can request different types of results from Open Context (see: https://opencontext.org/about/services#tab_query-meta). For instance, if you only want GeoJSON for the results of a search, add “response=geo-record” to the request. That will return just a list of geospatial features, without the metadata about the search, and without the facets. If you want a really simple list of URIs from a search, then add “response=uri”. Finally, if you want a simple list of search results with some descriptive attributes, add “response=uri-meta” to the search result.”&lt;/p&gt;

&lt;h2 id=&quot;json&quot;&gt;json&lt;/h2&gt;

&lt;p&gt;Json is not easy to work with. Fortunately, Matthew Lincoln has written an excellent tutorial on json and jq over at The Programming Historian which you should go read now. Read the ‘what is json?’ part, at the very least. In essence, json is a text file where keys are paired with values. JQ is a piece of software that enables us to reach into a json file, grab the data we want, and create either new json or csv. If you intend to visualize and explore data using some sort of spreadsheet program, then you’ll need to extract the data you want into a csv that your spreadsheet can digest. If you wanted to try something like d3 or some other dynamic library for generating web-based visualizations (eg p5js), you’ll need json.&lt;/p&gt;

&lt;h2 id=&quot;jqplay&quot;&gt;JQPLAY&lt;/h2&gt;

&lt;p&gt;JQ lets us do some fun filtering and parsing, but we won’t download and install it yet. Instead, we’ll load some sample data into a web-toy called jqplay. This will let us try different ideas out and see the results immediately. In the this file  called sample.json I have the query results from Open Context – Github recognizes that it is json and that it has geographic data within it, and turns it automatically into a map! To see the raw json, click on the &amp;lt; &amp;gt; button. Copy that data into the json box at jqplay.org.&lt;/p&gt;

&lt;p&gt;JQPlay will colour-code the json. Everything in red is a key, everything in black is a value. Keys can be nested, as represented by the indentation. Scroll down through the json – do you see any interesting key:value pairs? Matthew Lincoln’s tutorial at the programming historian is one of the most cogent explanations of how this works, and I do recommend you read that piece. Suffice to say, for now, that if you see an interesting key:value pair that you’d like to extract, you need to figure out just how deeply nested it is. For instance, there is a properties key that seems to have interesting information within it about dates, wares, contexts and so on. Perhaps we’d like to build a query using JQ that extracts that information into a csv. It’s within the features key pair, so try entering the following in the filter box:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.features [ ] | .properties&lt;/code&gt;
You should get something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;id&quot;: &quot;#geo-disc-tile-12023202222130313322&quot;,
  &quot;href&quot;: &quot;https://opencontext.org/search/?disc-geotile=12023202222130313322&amp;amp;prop=oc-gen-cat-object&amp;amp;rows=5&amp;amp;q=Poggio&quot;,
  &quot;label&quot;: &quot;Discovery region (1)&quot;,
  &quot;feature-type&quot;: &quot;discovery region (facet)&quot;,
  &quot;count&quot;: 12,
  &quot;early bce/ce&quot;: -700,
  &quot;late bce/ce&quot;: -535
}
{
  &quot;id&quot;: &quot;#geo-disc-tile-12023202222130313323&quot;,
  &quot;href&quot;: &quot;https://opencontext.org/search/?disc-geotile=12023202222130313323&amp;amp;prop=oc-gen-cat-object&amp;amp;rows=5&amp;amp;q=Poggio&quot;,
  &quot;label&quot;: &quot;Discovery region (2)&quot;,
  &quot;feature-type&quot;: &quot;discovery region (facet)&quot;,
  &quot;count&quot;: 25,
  &quot;early bce/ce&quot;: -700,
  &quot;late bce/ce&quot;: -535
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the exact syntax of why that works, see Lincoln’s tutorial. I’m going to just jump to the conclusion now. Let’s say we wanted to grab some of those keys within properties, and turn into a csv. We tell it to look inside features and find properties; then we tell it to make a new array with just those keys within properties we want; and then we tell it to pipe that information into comma-separated values. Try the following on the sample data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.features [ ] | .properties | [.label, .href, .&quot;context label&quot;, .&quot;early bce/ce&quot;, .&quot;late bce/ce&quot;, .&quot;item category&quot;, .snippet] | @csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…and make sure to tick the ‘raw output’ box at the top right. Ta da! You’ve culled the information of interest from a json file, into a csv. There’s a lot more you can do with jq, but this will get you started.&lt;/p&gt;

&lt;h2 id=&quot;get-jq-and-run-the-query-from-the-terminal-or-command-line&quot;&gt;GET JQ AND RUN THE QUERY FROM THE TERMINAL OR COMMAND LINE&lt;/h2&gt;

&lt;p&gt;Install on OS – instructions from Lincoln http://programminghistorian.org/lessons/json-and-jq#installation-on-os-x&lt;/p&gt;

&lt;p&gt;Install on PC – instructions from Lincoln http://programminghistorian.org/lessons/json-and-jq#installation-on-windows&lt;/p&gt;

&lt;p&gt;Got JQ installed? Good. Open your terminal or command prompt in the directory where you’ve got your json file with the data you extracted in part 1. Here we go:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jq -r &#39;.features [ ] | .properties | [.label, .href, .&quot;context label&quot;, .&quot;early bce/ce&quot;, .&quot;late bce/ce&quot;, .&quot;item category&quot;, .snippet] | @csv&#39; data.json &amp;gt; data.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, we invoke jq, we tell it we want the raw output (-r), we give it the filter to apply, we give it the file to apply it to, and we tell it what to name the output.&lt;/p&gt;

&lt;p&gt;Take a look at how Lincoln pipes the output of a wget command into jq at the end of the section on ‘invoking jq’. Do you see how we might accelerate this entire process the next time you want data out of Open Context?&lt;/p&gt;

&lt;h2 id=&quot;combining-wget--jq&quot;&gt;COMBINING WGET &amp;amp; JQ&lt;/h2&gt;

&lt;p&gt;Assuming you’ve got a list of urls (generated with our script from part 1), you point your firehose of downloaded data directly into jq. The crucial thing is to flag wget with &lt;code&gt;-qO-&lt;/code&gt; to tell it that the output will be &lt;em&gt;piped&lt;/em&gt; to another program. In which case, you would type at the terminal prompt or command line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget -qO- -i urls2.txt | jq -r &#39;.features [ ] | .properties | [.label, .href, .&quot;context label&quot;, .&quot;early bce/ce&quot;, .&quot;late bce/ce&quot;, .&quot;item category&quot;, .snippet] | @csv&#39; &amp;gt; out.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which in Human says, ” hey wget, grab all of the data at the urls in the list at urls2.txt and pipe that information into jq. JQ, you’re going to filter for raw output the information within properities (which is within features), in particular these fields. Split the information fields up via commas, and write everything to a new file called out.csv.”&lt;/p&gt;

&lt;p&gt;…Extremely cool, eh? (Word to the wise: read Ian’s tutorial on wget to learn how to form your wget requests politely so that you don’t overwhelm the servers. Wait a moment between requests – look at how the wget was formed in the open context part 1 post).&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 12:19:00 -0400</pubDate>
        <link>http://smgprojects.github.io/getting-data-out-of-opencontext/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/getting-data-out-of-opencontext/</guid>
        
        <category>how-to</category>
        
        <category>opencontext</category>
        
        <category>json</category>
        
        <category>data</category>
        
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>romans must die</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#romans-must-die&quot; id=&quot;markdown-toc-romans-must-die&quot;&gt;ROMANS MUST DIE&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#heads-will-roll&quot; id=&quot;markdown-toc-heads-will-roll&quot;&gt;HEADS WILL ROLL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-seductive-lure-of-the-digital-landscape&quot; id=&quot;markdown-toc-the-seductive-lure-of-the-digital-landscape&quot;&gt;THE SEDUCTIVE LURE OF THE DIGITAL LANDSCAPE&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#perspectives-on-space-and-time&quot; id=&quot;markdown-toc-perspectives-on-space-and-time&quot;&gt;PERSPECTIVES ON SPACE AND TIME&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#archaeogaming--simulation-as-a-kind-of-digital-public-archaeology&quot; id=&quot;markdown-toc-archaeogaming--simulation-as-a-kind-of-digital-public-archaeology&quot;&gt;ARCHAEOGAMING &amp;amp; SIMULATION AS A KIND OF DIGITAL PUBLIC ARCHAEOLOGY&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-useful-deaths-of-digital-romans&quot; id=&quot;markdown-toc-the-useful-deaths-of-digital-romans&quot;&gt;THE USEFUL DEATHS OF DIGITAL ROMANS&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#references-cited&quot; id=&quot;markdown-toc-references-cited&quot;&gt;REFERENCES CITED&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;romans-must-die&quot;&gt;ROMANS MUST DIE&lt;/h1&gt;
&lt;p&gt;Shawn Graham Carleton University&lt;/p&gt;

&lt;p&gt;Archaeologists have been simulating past societies via computation for decades (cf Wurzer et al 2015; Costopoulos and Lake 2010 for recent overviews). It is nothing new for us to perform a kind of practical necromancy to raise the dead to see what they can tell us. Archaeogaming introduces a new actor into these artificial societies: living humans. There are dangers to guard against, and opportunities to seize, when we co-write the past with our digital homunculi. In this chapter I draw on some of my own experiences to suggest a path forward on this quest.&lt;/p&gt;

&lt;h2 id=&quot;heads-will-roll&quot;&gt;HEADS WILL ROLL&lt;/h2&gt;
&lt;p&gt;Consider life in a small society run along patriarchal lines. The head of household’s word is law; perhaps even your household looks up to Him as well, in a chain of lesser families connected by kith and kin. All depends on your relationship with Him. Now consider a situation where He is suddenly removed – perhaps He has died suddenly. Your world wobbles a little bit, but succession rules quickly allow us to figure out who is now in charge. It is a rigid structure, yet it works. Most of the time.&lt;/p&gt;

&lt;p&gt;For now.&lt;/p&gt;

&lt;p&gt;But what would happen if many Heads rolled, all at once? If the Heads died in infamy and shame? How much damage can such a social world sustain before it collapses, recovers, or transforms? I am thinking now of the social world of the Romans in the late Republic or the early days of Empire, a world self-consciously rigid in the way I described, but yet, one that manages to carry on regardless. Let us, then, kill some Romans. It is perhaps one of the best way to understand the ways in which Roman society was resilient to the frequent pogroms and proscriptions of the late Republic and other eras because we can see what happens next.&lt;/p&gt;

&lt;p&gt;Romans must die for me to explore the ways Rome’s social network reacted under stress. This does of course present some obvious practical issues, but through simulation, one that is tractable. The kind of simulation I used was an ‘agent based simulation’ (ABM) (Graham, 2009 for the actual publication of this particular simulation). Think of an ABM as a kind of giant self-running, self-organizing petri dish. Each ‘agent’ is its own program, coded to react to its environment and/or the presence of other ‘agents’ (Lake 2015). Agent based modeling allows me to raise Romans from the dead over and over, and give them patterns of interaction known from the archaeology (for instance the stamps on Roman bricks in and around Rome fossilize nodes of social interaction, as it happens). I raise these digital Romans up; I give them artificial life; and then I kill them. Since the agents are programmed to interact based on social networks known to have existed in the past, aspects of their emergent behaviour are necessarily tied to that past (cf Epstein 2006: 31-33). Thus, since I wish to know under what circumstances this society might collapse, I have them interact in an economic and social world as known from the scholarly literature. My agents harbour grudges; they nurse wounds and social slights. Their primary motivation is to find chains of patrons and clients to whom they can attach in order to obtain resources; that is, a classic rich-get-richer effect is in play. Those who have not, get shut out. They take their revenge. And then I start to put this world under stress to see what happens next.&lt;/p&gt;

&lt;p&gt;There is something mesmerizing as I watch this artificial life creep and fight its way across the screen. As described, it is a giant petri dish, where my intervention is limited to setting up the pieces, writing the rules, and flipping the ‘on’ switch. But… wouldn’t you want to play this game? Climb the social ladder in Rome! Help your clients and find yourself better patrons – but make sure you don’t make too many enemies along the way or you too will lose… Game of Togas. It doesn’t take much to flip an agent model into a video game; it simply is a matter of whether or not the player/researcher has any active agency in what happens on the screen. In this regard then, archaeologists are already gamers. They use ABM to explore the past, but remove themselves from the action: thus an ABM is just a species of video game that plays itself. In which case, there is little reason why games-qua-games should not also be another kind of experimental petri dish for archaeologists to write the past.&lt;/p&gt;

&lt;h2 id=&quot;the-seductive-lure-of-the-digital-landscape&quot;&gt;THE SEDUCTIVE LURE OF THE DIGITAL LANDSCAPE&lt;/h2&gt;
&lt;p&gt;As I watch the screen and tell the story of what my digital Romans are up to, as they live and die, it becomes easier and easier to believe that I’m actually watching something true about the past…&lt;/p&gt;

&lt;p&gt;In Foucault’s Pendulum, Umberto Eco tells a story where the protagonists feed a computer with vast amounts of information, to devise a conspiracy theory, for their own entertainment, to determine a ‘truer’ story of European history. Things take a turn for the worse when the men begin to believe that the simulation is mapping out an actual ‘real’ truth – and even more dangerously, others come to believe in it too.&lt;/p&gt;

&lt;p&gt;This, it strikes me is a problem common both to gaming and to simulation. It is all too easy to succumb to the beauty of the digital landscape, a world that turns around me the player, me the creator. In both video games and agent simulations, we have a kind of control, an agency, we do not have in other aspects of our lives. This seductive power blinds us. When we are very good at a game, when we can anticipate what happens next and hit that state where the game is just challenging enough to keep us pushing forward, we have internalized the rules that govern the game and its story. To be ‘good’ at a game is to perform (uncritically) the vision of the world that its creators have encode in the rules, in the mechanics. When we are very good at simulation, we similarly have internalized the ways in which code can be used to tell stories of the world. In which case, if we are interested in archaeogaming, it might be worth thinking about the methods that have evolved to guard against this tendency in modelers. If we are interested in mere simulation, it might be worth thinking about the methods used to understand games to guard against this tendency in gamers.&lt;/p&gt;

&lt;p&gt;In which case it is useful to expand therefore on some of the ways agent modeling and video gaming might intersect, particularly in terms of how we evaluate the success or failure of both to ‘do good history’, as a contribution towards the methods of archaeogaming. After all, archaeology has always been concerned with understanding virtual worlds, whether those worlds are built from stone, wood, or concrete; it’s just that now we must understand the worlds built from sand and electricity as well.&lt;/p&gt;

&lt;h2 id=&quot;perspectives-on-space-and-time&quot;&gt;PERSPECTIVES ON SPACE AND TIME&lt;/h2&gt;
&lt;p&gt;The difference between games and agent simulations is not so vast. An agent based model in fact is a special class of video game where the player, does not, in fact, play. She sets it all up, and she watches to see how that world reacts. She’s interested in the whole-world interrelationships; the player of games on the other hand is necessarily interested in the reactions to his own actions. In some respects, one could make the analogy to social network analysis: simulation is to whole-network analysis as a video game is to ego-analysis (cf Weingart 2011-2012 on network analysis). That is to say, the difference is one of perspective.&lt;/p&gt;

&lt;p&gt;If archaeogaming is going to be a serious pursuit, then the first lesson we can take from agent modeling concerns time and space. The way that time is treated in agent models is critical; time is malleable so that there is time for something to take place. It makes a difference to your model whether or not your agents update themselves one-at-a-time, each one running its procedures sequentially, versus in parallel. Emergent effects that can seem profound or meaningful might only be an artefact of how ‘time’ is imagined. Then there is the time within which something might take place. Terry Pratchett’s ‘Thief of Time’ (2001) calls this the ‘universal tick’, or the time it takes for now to become then. Agent models tick in time with the computer’s clock: does processor-clock time have any meaningful analogy to ‘historical time’? Similarly, agent models happen in a kind of space. This space can be a flat two dimensional world subject to edge effects that can muddy the waters; in some models, the left hand side of the world connects to the right hand side, and the top connects to the bottom, which gives us a torus. In others, the space is the gaps between social actors, that is, a network. How does space work in the games we are analyzing from an archaeogamer perspective?&lt;/p&gt;

&lt;p&gt;Aarseth et al. years ago devised a typology for video games that depended upon considering several axes of analysis – space, time, player-structure, control, and rules (2003). As we begin to devise the methods for archaeogaming, I want to suggest that we pay attention to space and time in their formulation: Space contains ‘perspective, topography, and environment’; Time contains ‘pace, representation’ and ‘teleology’. Whether the virtual world we are analyzing is in ‘meatspace’ or cyberspace, these categories usefully force us to concentrate on what space and time are doing in the game/simulation in meaningful ways. Consider my simulation of Roman social life where the Romans must die. In terms of ‘space’, the simulation has an omni-present perspective: I see all, I can peer into each agent’s life at will. The environment is geometric; the world in which these Romans move is static, the conditions do not change during the run. In terms of ‘time’, the pace is turn-based (each Roman updates in turn), time is mimetic (it takes time for the Roman to achieve something), time is teleological in that the Romans have clear goals and ambitions in mind. As table 1 shows, my simulation occupies an interesting space between ‘Caesar IV’ ref,link and ‘Civilization IV’ ref, link , two games that also contain useful simulations of Roman society.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                              Caesar IV     Civilization IV     RmD
Space           Perspective     Omni-Present    Vagrant             Omni-Present
              Topography      Topological     Geometrical         Geometric
              Environment       Dynamic       Dynamic             Static
Time            Pace              Real-Time     Turn-Based          Turn-Based
              Representation    Arbitrary       Mimetic             Mimetic
              Teleology       Finite          Finite              Finite Table 1 Comparing time and space in games and an agent based model. An expansion of Kee and Graham (2014) Table 13.2.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s put the shoe on the other foot. How do Caesar IV and CiV hold up against the standards used to understand agent based models? Let us use Iza Romanowska’s framework (2014; see also her longer discussion 2015) for evaluating agent models. For Romanowska, the key elements to usefully evaluating the success of an agent based model are:&lt;/p&gt;

&lt;p&gt;scope
appropriateness
resolution
how complicated is it?
parsimonious parameters
utility&lt;/p&gt;

&lt;p&gt;Scope and appropriateness deal with research questions. Are we building a model to explore a hypothetical or to understand patterns in the data? Caesar IV clearly has a research question at its heart: how does experience in the provinces make a man fit to govern in Rome? When I reframed ‘Romans must die’ as a game in my opening, – help your clients succeed, find a patron to help you succeed – I was framing a question about the role of patronage in generating social structure in Rome. Appropriateness: is a resource management sim an appropriate tool for answering the question about governance? Resolution: Caesar IV shows me individual Romans, with whom I have to interact. That may be too low a level given the scope &amp;amp; appropriateness. Parsimonious parameters – how many knobs and dials can I twiddle? What and where are the feedback loops? Complexity theory here teaches that simpler is better (Romanowska, 2015). Utility: not, is this a ‘fun’ game, but rather, ‘what have we learned?’ How are we changed?&lt;/p&gt;

&lt;h2 id=&quot;archaeogaming--simulation-as-a-kind-of-digital-public-archaeology&quot;&gt;ARCHAEOGAMING &amp;amp; SIMULATION AS A KIND OF DIGITAL PUBLIC ARCHAEOLOGY&lt;/h2&gt;
&lt;p&gt;Finally, I put it to you that one of the most powerful ways that archaeogaming could intersect with a digital public archaeology becomes evident if we consider the original purpose of the Netlogo agent based modeling environment (currently, the most widely used ABM tool in archaeology). Netlogo was originally designed to teach students about complex phenomena by getting them to observe the ways small parameter changes could affect the global behaviour of the complex system (Wilensky, 1999). The ‘Evolving Planet’ archaeogame (Rubio et al, this volume) takes this approach. But we could go further. What if we put the players into our agent-based models? Not just tweaking the global, but engaging the first-person? Holistic and Ego-centric at the same time. Netlogo comes with an extension called ‘hubnet’, which allows individuals to take on the role of a single agent within an otherwise fully digital simulation. The Netlogo developers call this ‘participatory’ simulation’. Is there room in archaeogaming to merge humans and machine-made societies? That tools change us and what it means to be human is a truism of archaeology: archaegaming perhaps is a way to understand what this digital moment is doing to our humanity.&lt;/p&gt;

&lt;h2 id=&quot;the-useful-deaths-of-digital-romans&quot;&gt;THE USEFUL DEATHS OF DIGITAL ROMANS&lt;/h2&gt;
&lt;p&gt;Archaeologists are naturally gamers already. Archaeologists have been building virtual worlds long before video games emerged. We have already developed methods and techniques for understanding the virtual worlds of the past; the things we see as archaeologists in the virtual worlds of the present accordingly can be grounded in the methods and techniques of archaeology. This small essay has suggested a framework based on typologies of time and space coupled with perspectives on agent modeling validation techniques to help guard against the seductive lure of the digital, so that when Romans must die, the die usefully.&lt;/p&gt;

&lt;h2 id=&quot;references-cited&quot;&gt;REFERENCES CITED&lt;/h2&gt;
&lt;p&gt;Costopoulos, A., M.W. Lake (editors) 2010 Archaeological Simulation: Into the 21st Century. University of Utah Press, Salt Lake City.&lt;/p&gt;

&lt;p&gt;Epstein, J. 2006 Agent-based computational models and generative social science. In Generative Social Science: Studies in Agent-Based Computational Modeling, edited by J. M. Epstein, pp. 4-46. Princeton UP, Princeton, NJ.&lt;/p&gt;

&lt;p&gt;Espen Aarseth, Solveig M. Smedstad, and Lise Sunnana 2003 A Multi-Dimensional Typology of Games._ Proceedings of the Level Up Games Conference_. pp 48-53. Netherlands Digital Games Research Association, Utrecht.&lt;/p&gt;

&lt;p&gt;Graham, Shawn 2009 Behaviour Space: Simulating Roman Social Life and Civil Violence. Digital Studies / Le champ numÃ©rique 1.2 http://www.digitalstudies.org/ojs/index.php/digital_studies/article/view/172/214&lt;/p&gt;

&lt;p&gt;Kee, Kevin and Shawn Graham 2014 Teaching history in an age of pervasive computing: the case for games in the high school and undergraduate classroom in Pastplay: Teaching and Learning History with Technology, edited by Kevin Kee, pp337-366. University of Michigan Press, Ann Arbor MI.&lt;/p&gt;

&lt;p&gt;Lake, M.W. 2015 Explaining the past with ABM: On modelling philosophy. In Agent-based modeling and simulation in archaeology, edited by G. Wurzer, Kerstin Kowarik, and Hans Reschreiter, pp. 3-35. Springer, Vienna.&lt;/p&gt;

&lt;p&gt;Romanowska, Iza 2014 How to evaluate a simulation: a quick guide for non-modellers Simulating Complexity https://simulatingcomplexity.wordpress.com/2014/10/06/how-to-evaluate-a-simulation-a-quick-guide-for-non-modellers/&lt;/p&gt;

&lt;p&gt;Romanowska, Iza 2015 So You Think You Can Model? A Guide to Building and Evaluating Archaeological Simulation Models of Dispersals Human Biology 87(3):169-192. http://www.bioone.org/doi/full/10.13110/humanbiology.87.3.0169&lt;/p&gt;

&lt;p&gt;Weingart, Scott. 2011-12 Demystifying Networks, Parts I &amp;amp; II. Journal of Digital Humanities http://journalofdigitalhumanities.org/1-1/demystifying-networks-by-scott-weingart/&lt;/p&gt;

&lt;p&gt;Wurzer, G, Kerstin Kowarik, and Hans Reschreiter (editors) 2015 Agent-based modeling and simulation in archaeology. Springer, Vienna.&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 12:18:00 -0400</pubDate>
        <link>http://smgprojects.github.io/romans-must-die/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/romans-must-die/</guid>
        
        <category>agent based modeling</category>
        
        <category>archaeogaming</category>
        
        
        <category>Essays</category>
        
      </item>
    
      <item>
        <title>notes on running the dh usb</title>
        <description>
&lt;p&gt;Our digital archaeology textbook will be intertwined with an instance of the DHBox. One of the participants in that project is Jonathan Reeve, who has been building a version that runs off a bootable USB. So naturally, I had to give it a spin. I ran out, got a new usb stick and….&lt;/p&gt;

&lt;p&gt;…had to figure out Bittorrent. Every time I went to install the client, every browser I had on every machine kept blocking it as malicious. Normally I can work around this sort of thing, but it was really pernicious. Turned out, my stable of computers were all quite happy with uTorrent instead. With that installed, I grabbed the torrent files from the DH-USB repository, and let them do their magic. It took 3 hrs to get the full .img file.&lt;/p&gt;

&lt;p&gt;…had to figure out how to put that .img onto a usb stick such that it would be bootable. Unetbootin should’ve worked, but didn’t. In the end, I had to do it from the command line, per the ‘alternative instructions’:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;MacOS: Identify the label of your USB drive with the command diskutil list. Then unmount the disk with diskutil unmountDisk /dev/diskX, replacing diskX with your drive name. Finally, run sudo dd if=/path/to/dh-usb.img of=/dev/rdiskX bs=1m again replacing /path/to/dh-usb.img with the path to the .img file, and diskX with the name of your disk.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then I had to figure out how to get the damned machines to boot from the stick rather than their own hard drive. On the Mac, this was easy – just hold the alt key down while the machine powers up, and you can then select the usb stick. NB: you can also, it seems, select whatever wifi network happens to be in the air at this stage, but if you do this (I did) everything will go sproing shortly thereafter and the stick won’t boot. So don’t do this. On the Windows 10 machine I had access to, booting up from a disk or stick is no longer the straight-forward ‘hold down f11’ or whatever anymore. No, you have to search for the ‘advanced startup’ options, and then find the boot from disk option, where  you specify the usb stick. THEN the machine powers down and up again… and will tell you that the security settings won’t let you proceed any further. Apparently, there’s a setting somewhere in the BIOS that you have to switch, but as it wasn’t my machine and I’d had enough, I abandoned it. Windows folks, godspeed. (Incidentally, for various reasons, computers much older than about five years are out of luck, as some key pieces of ur-code have changed in recent years:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[you need] a modern system that supports UEFI. Legacy BIOS boot may be possible, but it hasn’t been extensively tested&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I had some other issues subsequent as I tried to install R and R Studio, but I’ve sorted those out with Jonathan and by the time you read this, they probably won’t be issues any more (but you can click on the ‘closed issues’ on the repo to see what my issues were). One thing that drove me nuts was trying to persuade Arch Linux to find the damned wifi.&lt;/p&gt;

&lt;p&gt;I eventually stumbled across this re ubuntu: https://help.ubuntu.com/community/WifiDocs/Driver/bcm43xx&lt;/p&gt;

&lt;p&gt;so tried this:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ lspci -vvnn | grep -A 9 Network&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and saw that I had kernal modules: brcmfmac, wl, but none in use. So I tried this:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo modprobe brcmfmac&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and ran the first command again; kernal now in use!&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo wifi-menu&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;…and connected. Kept getting connection errors; went to settings &amp;gt; network and connected through there, ta da!&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 11:59:00 -0400</pubDate>
        <link>http://smgprojects.github.io/notes-on-running-the-dh-usb/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/notes-on-running-the-dh-usb/</guid>
        
        <category>platforms</category>
        
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>tracery on glitch</title>
        <description>
&lt;p&gt;Lovecraftian archaeology via tracery.io [https://smgprojects.github.io/bots/traceryWeb/]&lt;/p&gt;

&lt;p&gt;[http://glitch.com]. This site allows you to remix and deploy others’ code. So I rewrote the site report generator and moved it to Glitch; you can see it in action at [https://lovecraftian-archaeology.glitch.me/] and if you want to remix it go to the edit page. The key file you’ll want to edit is grammar.js . You could start by swapping in some of these examples but note:&lt;/p&gt;

&lt;p&gt;In grammar.js, you see:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var grammar = {
        title : [&quot;Draft Report&quot;],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But in that example gist I linked to, you see&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&quot;origin&quot;: [&quot;I accuse #suspect# of committing the crime in the #room# with the #weapon#!&quot;],
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The grammar.js file does not put quotations around the key. So keep an eye out for that if you’re pasting from someone else’s project; paste from the opening { to the closing }. Also, origin is where the actual text will be generated from. So you compose your work by wrapping text around #keys# as in the second example.&lt;/p&gt;

&lt;p&gt;Sorry. That’s a pretty awful explanation. Give the Tracery.io editor a spin to get the hang of it.  This is a really nice tutorial too.&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 11:48:00 -0400</pubDate>
        <link>http://smgprojects.github.io/tracery-on-glitch/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/tracery-on-glitch/</guid>
        
        <category>tracery</category>
        
        <category>procedural generation</category>
        
        <category>glitch</category>
        
        
        <category>Experiments</category>
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>the workflow in this notebook</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#a-reminder&quot; id=&quot;markdown-toc-a-reminder&quot;&gt;A Reminder&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;a-reminder&quot;&gt;A Reminder&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;terminal in the smgprojects folder&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;rake draft&lt;/code&gt; to create a new note in the drafts folder&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;rake write&lt;/code&gt; to open all notes in the draft folder&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;rake publish&lt;/code&gt; to move notes to the source folder&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;make&lt;/code&gt; to make the damned site&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;rake togithub&lt;/code&gt; to put the built site in the github repo&lt;/li&gt;
  &lt;li&gt;push to github.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 11:39:00 -0400</pubDate>
        <link>http://smgprojects.github.io/the-workflow-in-this-notebook/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/the-workflow-in-this-notebook/</guid>
        
        <category>workflow</category>
        
        
        <category>Meta</category>
        
      </item>
    
      <item>
        <title>running torch-rnn in docker on my mac</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#experimenting-with-a-recurrent-neural-network-package&quot; id=&quot;markdown-toc-experimenting-with-a-recurrent-neural-network-package&quot;&gt;experimenting with a recurrent neural network package&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-i-was-trying-to-do&quot; id=&quot;markdown-toc-what-i-was-trying-to-do&quot;&gt;what I was trying to do&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-i-did&quot; id=&quot;markdown-toc-what-i-did&quot;&gt;what I did&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#things-that-were-hard&quot; id=&quot;markdown-toc-things-that-were-hard&quot;&gt;things that were hard&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#thoughts-on-where-to-go-next&quot; id=&quot;markdown-toc-thoughts-on-where-to-go-next&quot;&gt;thoughts on where to go next&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;experimenting-with-a-recurrent-neural-network-package&quot;&gt;experimenting with a recurrent neural network package&lt;/h1&gt;

&lt;h2 id=&quot;what-i-was-trying-to-do&quot;&gt;what I was trying to do&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;I was curious to figure out if I could train the computer to write an Indiana Jones script. To do this, you put together a file to show the computer what such a script looks like. This is the ‘training’ file, or the input.txt&lt;/li&gt;
  &lt;li&gt;I googled until I found the scripts. I used Raiders, Temple of Doom, and Last Crusade&lt;/li&gt;
  &lt;li&gt;reading the documentation for &lt;a href=&quot;https://github.com/karpathy/char-rnn&quot;&gt;char-rnn&lt;/a&gt; I realized that was too small, so I added Goonies and the Brendan Frasier Mummy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-i-did&quot;&gt;what I did&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;I followed the instructions at https://github.com/karpathy/char-rnn to download and install the char-rnn package&lt;/li&gt;
  &lt;li&gt;the last instruction, about sourcing, I had to re-run when I logged back into dhbox&lt;/li&gt;
  &lt;li&gt;today’s history.txt file is &lt;a href=&quot;june21-todays-history-file.txt&quot;&gt;june21-todays-history-file.txt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;things-that-were-hard&quot;&gt;things that were hard&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;getting the data. I went to gist.github.com and made a file, &lt;a href=&quot;https://gist.github.com/shawngraham/af1edaa5b40be09d643a4700bb2150af&quot;&gt;input.txt&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;I used curl to download it to the data folder, but had to find the ‘raw’ version, otherwise i just got the html that wraps the gist page. Raw version is behind the raw button on the page, [here](https://gist.githubusercontent.com/shawngraham/af1edaa5b40be09d643a4700bb2150af/raw/14c6a48715f20725256b9b2ccd13eeb3a3372fcd/input.txt]&lt;/li&gt;
  &lt;li&gt;trained the rnn with this command: &lt;code&gt;th train.lua -data_dir data/input.txt -rnn_size 512 -num_layers 2 -dropout 0.5&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;came back the next day, when it finished running (which is today). Had to enter the source command again before dhbox remembered where torch was installed - i cd’d into the torch folder to do that&lt;/li&gt;
  &lt;li&gt;‘sampled’ the model - this runs the generate-a-new-script thing &lt;code&gt;th sample.lua cv/some_checkpoint.t7 -gpuid -1&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;had to ls the cv folder so I would know the file name for the last checkpoint.&lt;/li&gt;
  &lt;li&gt;this printed the result to the screen; to do it to a file I added the &amp;gt; filename thing: &lt;code&gt;th sample.lua cv/some_checkpoint.t7 -gpuid -1 &amp;gt; script.txt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;thoughts-on-where-to-go-next&quot;&gt;thoughts on where to go next&lt;/h2&gt;

&lt;p&gt;this ends the example. You could link to annotations you made, things you’ve seen, work that this entry is in dialog with, and so on.&lt;/p&gt;

&lt;p&gt;Note what is in this repo: a description of what I was up to; the results of my &lt;code&gt;$ history &amp;gt; todayshistory.txt&lt;/code&gt; command, the output of what I was trying to do, links to other things I used/created in the course of the experiment. You can make one repo with many folders, or many repos of just one folder, but whatever you do, try to keep everything together in a logical manner.&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Jun 2017 11:35:00 -0400</pubDate>
        <link>http://smgprojects.github.io/running-torch-rnn-in-docker-on-my-mac/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/running-torch-rnn-in-docker-on-my-mac/</guid>
        
        <category>experiment</category>
        
        <category>rnn</category>
        
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>cradle</title>
        <description>
&lt;p&gt;Storytelling does a lot of work in ABM, although we don’t really acknowledge it as such. When you insert a player into the middle of an ABM, storytelling is your way of equipping the player with what she needs to know in order to survive, much like Sweeper tells Sam Vimes. So, I’m experimenting with Cradle which enables Twine and Twine-like storytelling within Unity.&lt;/p&gt;

&lt;p&gt;Things to know about &lt;a href=&quot;https://github.com/daterre/Cradle&quot;&gt;Cradle&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;the last release is out of date, so don’t bother using it
download the repo, unzip, and use it to start a new Unity project (Start up unity, open a new project, and select the ‘cradle-master’ folder. Contrary to the readme, don’t try installing it in an existing Unity project yet. This is because the repo appears to be his actual project.
I kept getting an error in the logs concerning some error in one of the ‘test’ files. I can’t recall at the moment, and I can’t check because I’m at the wrong machine, so I’ll have to come back to this point. Commenting out the offending line solved the problem.
Drop your Twine file (twee or html) into the main Assets folder for your project. Cradle will convert that into C# for you.
Drag TwinePlayer prefab into the scene and then make sure to inspect it; add script to get it to point to your C# twine file.
Ta da.
Export as package, and select the relevant files (ie, you don’t need all of the assets or example game files etc) and then you can drag it into any other projects you have on the run.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Apr 2017 11:47:00 -0400</pubDate>
        <link>http://smgprojects.github.io/cradle/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/cradle/</guid>
        
        <category>archaeogaming</category>
        
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>tracery to write music</title>
        <description>
&lt;p&gt;I came across this short piece by &lt;a href=&quot;http://www.codingblocks.net/videos/generating-music-in-javascript/&quot;&gt;Joe Zach&lt;/a&gt; where he uses tracery to generate a sequence of chords (the names of chords) which he then feeds into another library, &lt;a href=&quot;https://www.npmjs.com/package/scribbletune&quot;&gt;scribbletune&lt;/a&gt; to write those chords to a midi file.&lt;/p&gt;

&lt;p&gt;https://github.com/shawngraham/mini-code-adventures-generate-music-with-js/blob/master/index.js&lt;/p&gt;

&lt;p&gt;Give it a listen: https://soundcloud.com/shawn-graham-60451318/sand&lt;/p&gt;

&lt;p&gt;I’m thinking that this could be plumbed into a twitter bot somehow, write the midi overtop of an autoplaying video…? I dunno.&lt;/p&gt;
</description>
        <pubDate>Fri, 07 Apr 2017 11:51:00 -0400</pubDate>
        <link>http://smgprojects.github.io/tracery-to-write-music/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/tracery-to-write-music/</guid>
        
        <category>tracery</category>
        
        <category>procedural generation</category>
        
        <category>music</category>
        
        
        <category>Experiments</category>
        
        <category>Code</category>
        
      </item>
    
      <item>
        <title>writing with bookdown</title>
        <description>
&lt;p&gt;For my current project, the Open Digital Archaeology Textbook Environment (ODATE for short; I’m rubbish at a) names and b) acronyms) Neha, Michael, Beth and I are trying to use Slack to manage our conversations, and writing instead in a series of markdown files, and use a repo to manage the collaboration, resolve conflicts, etc. Right now this is going swimmingly because for various reasons the rest of the gang can’t devote any time to this project. For my part, I’m trying to get the infrastructure and preliminary writing set up so we can hit the ground running in around mid march.&lt;/p&gt;

&lt;p&gt;Given our requirements outlined above, I looked around at a couple of different platforms, settling eventually on Bookdown . I like Bookdown because I can write in whatever editor strikes my fancy (switching into R to do the build) and it will give me a complete flat website (&lt;em&gt;with&lt;/em&gt; search), an epub, and a PDF, grabbing my citations from a Bibtext file and formatting appropriately (we have a collaborative Zotero library for adding to while we write/research; export to Bibtext, boom!). Right now, I’m writing within RStudio. With some minimal tweaking, it also allows me to build in Hypothes.is collaborative annotation (and via the Hypothesis API, I plan on collating annotations periodically to guid revisioning and also perhaps to build into the book user appendices, but that idea is still nebulous at the moment). I’ve also run the resulting website from Bookdown through various web accessibility tools, and the report comes back fairly positive. With some more tweaking, I think I can make the final product super-accessible, or at the very least, produce PDFs that screenreaders and so on can work with.&lt;/p&gt;

&lt;p&gt;Getting Bookdown set up was not without its idiosyncracies. The RStudio version has to be the preview release. Then:&lt;/p&gt;

&lt;p&gt;create a new project in RStudio (do this in a brand new folder)
run the following script to install Bookdown:
&lt;code&gt;
install.packages(&quot;devtools&quot;)
devtools::install_github(&quot;rstudio/bookdown&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;create a new textfile with metadata that describe how the book will be built. The metadata is in a format called YAML (‘yet another markup language’) that uses keys and values that get passed into other parts of Bookdown:
&lt;code&gt;
title: &quot;The archaeology of spoons&quot;
author: &quot;Graham, Gupta, Carter, &amp;amp; Compton&quot;
date: &quot;July 1 2017&quot;
description: &quot;A book about cocleararchaeology.&quot;
github-repo: &quot;my-github-account/my-project&quot;
cover-image: &quot;images/cover.png&quot;
url: &#39;https\://my-domain-ex/my-project/&#39;
bibliography: myproject.bib
biblio-style: apa-like
link-citations: yes
&lt;/code&gt;
This is the only thing you need to have in this file, which is saved in the project folder as index.Rmd.&lt;/p&gt;

&lt;p&gt;Write! We write the content of this book as text files, saving the parts in order. Each file should be numbered 01-introduction.Rmd, 02-a-history-of-spoons.Rmd, 03-the-spoons-of-site-x.Rmd and so on.
Build the book. With Bookdown installed, there will be a ‘Build Book’ button in the R Studio build pane. This will generate the static html files for the book, the pdf, and the epub. All of these will be found in a new folder in your project, &lt;code&gt;_book&lt;/code&gt;. There are many more customizations that can be done, but that is sufficient to get one started.
To get Hypothesis working, we have to modify the &lt;code&gt;_output.yml&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bookdown::gitbook:
  includes:
      in_header: hypothesis.html
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That html file is just a file with a single line, where you add the script src line for embedding hypothesis (see this guidance).&lt;/p&gt;

&lt;p&gt;You end up with a Gitbook-looking site.&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Feb 2017 11:56:00 -0500</pubDate>
        <link>http://smgprojects.github.io/writing-with-bookdown/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/writing-with-bookdown/</guid>
        
        <category>ODATE</category>
        
        <category>writing</category>
        
        <category>platform</category>
        
        <category>static site generator</category>
        
        
        <category>Meta</category>
        
      </item>
    
  </channel>
</rss>
