<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shawn Graham&#39;s Open Digital Humanities Notebook 2016-17</title>
    <description>An open history notebook forked from Jason Heppler</description>
    <link>http://smgprojects.github.io/</link>
    <atom:link href="http://smgprojects.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 11 May 2016 10:05:49 -0400</pubDate>
    <lastBuildDate>Wed, 11 May 2016 10:05:49 -0400</lastBuildDate>
    <generator>Jekyll v3.1.3</generator>
    
      <item>
        <title>Experiment - Bad Equity</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#source-materials&quot; id=&quot;markdown-toc-source-materials&quot;&gt;Source Materials&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#step-1-obtaining-the-text-files&quot; id=&quot;markdown-toc-step-1-obtaining-the-text-files&quot;&gt;Step 1. Obtaining the text files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#step-2-has-anyone-else-tried-to-do-this&quot; id=&quot;markdown-toc-step-2-has-anyone-else-tried-to-do-this&quot;&gt;Step 2. Has anyone else tried to do this?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#step-3-ryans-scripts&quot; id=&quot;markdown-toc-step-3-ryans-scripts&quot;&gt;Step 3. Ryan’s scripts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#step-4-counting-special-characters&quot; id=&quot;markdown-toc-step-4-counting-special-characters&quot;&gt;Step 4. Counting Special characters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#step-5-visualizing-the-results-how-bad-is-my-ocr&quot; id=&quot;markdown-toc-step-5-visualizing-the-results-how-bad-is-my-ocr&quot;&gt;Step 5: ‘Visualizing’ the results: How bad is my OCR?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#result&quot; id=&quot;markdown-toc-result&quot;&gt;Result&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-have-i-learned&quot; id=&quot;markdown-toc-what-have-i-learned&quot;&gt;What have I learned?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#to-do-next&quot; id=&quot;markdown-toc-to-do-next&quot;&gt;To do next:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;source-materials&quot;&gt;Source Materials&lt;/h2&gt;
&lt;p&gt;The Shawville &lt;a href=&quot;http://theequity.ca/&quot;&gt;Equity&lt;/a&gt; is a weekly newspaper published in Shawville Quebec. It has published continuously since 1883, when it was first published in the county seat, Bryson. Recently, the Provincial Archives of Quebec (‘&lt;a href=&quot;http://collections.banq.qc.ca/&quot;&gt;Bibliotheque et Archives Nationales du Quebec&lt;/a&gt;’) scanned and OCR’d the &lt;a href=&quot;http://collections.banq.qc.ca:8008/jrn03/equity/src/&quot;&gt;run from 1883 to 2010&lt;/a&gt;, using the materials held at the Equity’s office, as part of a larger project to scan the journals of Quebec’s long-established English communities.&lt;/p&gt;

&lt;p&gt;I initially thought I would have to download all of the pdfs and extract the text layer from those, but in the repo, both the pdf and the txt file are available as separate files. I’ve re-posted an example &lt;a href=&quot;https://gist.github.com/shawngraham/8323899898cf016d5829f68394e63699&quot;&gt;text file here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I wondered: how good is the OCR? And, without manually checking each text file, can I auto-magically generate some sort of proxy for assessing this?&lt;/p&gt;

&lt;h2 id=&quot;step-1-obtaining-the-text-files&quot;&gt;Step 1. Obtaining the text files&lt;/h2&gt;
&lt;p&gt;Obtaining the text files was just a matter of correctly formatting a &lt;code&gt;wget&lt;/code&gt; command. For whatever reason, I had a &lt;em&gt;lot&lt;/em&gt; of trouble doing this. All I really needed to do was point wget at this directory:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://collections.banq.qc.ca:8008/jrn03/equity/src/&quot;&gt;http://collections.banq.qc.ca:8008/jrn03/equity/src/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;like so:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget http://collections.banq.qc.ca:8008/jrn03/equity/src/ -A .txt -r --no-parent -nd –w 2 --limit-rate=10k&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;but, for whatever reason, I felt I needed to generate a list of urls first, and &lt;em&gt;then&lt;/em&gt; point wget at it. My &lt;code&gt;urlgenerator.py&lt;/code&gt; was derived from the Programming Historian lesson on &lt;a href=&quot;http://programminghistorian.org/lessons/applied-archival-downloading-with-wget&quot;&gt;applied archival downloading&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;urls = &#39;&#39;;
f=open(&#39;urls.txt&#39;,&#39;w&#39;)
for x in range(1883, 2011):
    urls = &#39;http://collections.banq.qc.ca:8008/jrn03/equity/src/%d/\n&#39; % (x)
    f.write(urls)
f.close
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ben also suggested a way of doing this in Ruby, to get right down to the month &amp;amp; day subdirectories:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Ruby&quot;&gt;t=Time.new(1883,05,01)
400.times { print&quot;http://collections.banq.qc.ca:8008/jrn03/equity/src/#{t.year}/#{t.month}/#{t.day}/83471_#{t.year}-#{t.month}-#{t.day}.pdf\n&quot;; t += 6*24*60*60 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…although because the archives uses leading zeros for months 1 - 9 and days 1 - 9, some more fiddling is required. In the end, if I could’ve just sussed wget properly in the first place… ah well. Learning Ruby is clearly something I need to do.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I downloaded every edition from 1883 through to the end of 1914, 1595 files. This took the better part of a day.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;step-2-has-anyone-else-tried-to-do-this&quot;&gt;Step 2. Has anyone else tried to do this?&lt;/h2&gt;

&lt;p&gt;And the answer is, yes, yes they have. A quick question on Twitter brought me to this post by &lt;a href=&quot;https://ryanfb.github.io/etc/2015/03/16/automatic_evaluation_of_ocr_quality.html&quot;&gt;Ryan Baumann, Assessing OCR Quality&lt;/a&gt;. Later, I also had an excellent discussion with Ben Brumfield who pointed me to his work on &lt;a href=&quot;http://manuscripttranscription.blogspot.ca/2013/02/detecting-handwriting-in-ocr-text.html&quot;&gt;detecting handwriting in OCR’d texts&lt;/a&gt; and &lt;a href=&quot;https://github.com/idigbio-aocr/HandwritingDetection/blob/master/code/find_labels_with_handwriting.rb&quot;&gt;code for the same&lt;/a&gt;. I haven’t tried Ben’s script yet. Below, I discuss trying to get Ryan’s approach to work&lt;/p&gt;

&lt;h2 id=&quot;step-3-ryans-scripts&quot;&gt;Step 3. Ryan’s scripts&lt;/h2&gt;
&lt;p&gt;Ryan’s scripts work by automatically detecting the language of each line in the ocr’d text. It uses a python module called &lt;code&gt;[langid](https://github.com/saffsd/langid.py)&lt;/code&gt; to determine the probability that a text is in a particular language. Badly OCR’d lines make determining this difficult. His two scripts (&lt;a href=&quot;https://gist.github.com/ryanfb/0ee1082a597e200ca8c3#file-scorelines-sh&quot;&gt;scorelines.sh&lt;/a&gt; and &lt;a href=&quot;https://gist.github.com/ryanfb/c9bd9a1ce0f6f7cb2a45#file-ocrquality-rb&quot;&gt;ocrquality.rb&lt;/a&gt;) eventually should result in a value between 0 and 1 where 0 indicates no problem in assessing the language, hence, good OCR. (See Ryan’s &lt;a href=&quot;https://twitter.com/ryanfb/status/730085822817566721&quot;&gt;tweet&lt;/a&gt;).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;first hiccup: &lt;code&gt;chmod&lt;/code&gt;. Forgot I had to &lt;code&gt;sudo chmod 700 scorelines.sh&lt;/code&gt; etc so that they’d work.&lt;/li&gt;
  &lt;li&gt;second hiccup: depending on the txt file, the scripts would work, or crash spectacularly with a wide variety of errors. Because of that variety, my suspicion is that special characters in the text file - or possibly (probably?) weird encoding - is causing the scripts to break. A long trawl of stackexchange had me try &lt;code&gt;LANG=C&lt;/code&gt; pre-pended, eg,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;$ LANG=C ./scorelines.sh filename.txt | ./ocrquality.rb&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and again, sometimes it worked, sometimes it didn’t. If I ran &lt;code&gt;scorelines.sh&lt;/code&gt; on its own, piping the output to file, which I then fed into &lt;code&gt;ocrquality.rb&lt;/code&gt;, sometimes that would work when the two commands piped together wouldn’t. And sometimes not. The only common denominator was the txt file itself.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In which case, could the count of special characters be taken as a proxy for bad OCR?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;it’s at this point that I should return to Ben’s script, which parses each file with regex to count the myriad ways OCR can break, and creates a kind of tabular record of the same. For his purposes - identifying handwriting in printed text - this gives him an indication of which files to peruse more carefully. In a twitter exchange, we talked about ‘why special characters?’. I showed him the sample txt (linked above) and he noted that I had way more special characters than him. This got me to thinking: what about Ryan Cordell’s post on ‘&lt;a href=&quot;http://ryancordell.org/research/qijtb-the-raven/&quot;&gt;Qijtb the Raven&lt;/a&gt;?’. He uses &lt;a href=&quot;http://www.sno.phy.queensu.ca/~phil/exiftool/&quot;&gt;exiftool&lt;/a&gt; to see the metadata in the pdfs, which gives him crucial information on how the pdfs were generated. &lt;strong&gt;I need to do this too&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;At any rate, at this point, I wondered two things: 1) how carefully did they set up their OCR? and 2) is this related to the (likely?) possibility that the person running the OCR application does not speak English as a first language? Is there a quality control issue at play during the process of scanning?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;step-4-counting-special-characters&quot;&gt;Step 4. Counting Special characters&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;a script to count special characters was actually hard to find. I tried &lt;code&gt;wc&lt;/code&gt; at first, to see if that could give me any useful output:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;find . -name &#39;*.txt&#39; | xargs wc&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;…which, when piped to file, would give me the number of lines, number of words, and number of bytes. This output did not seem meaningful.
- more perusal of stackexchange found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;for f in *.txt; do
python -c &quot;import collections, pprint; pprint.pprint(dict(collections.Counter(open(&#39;$f&#39;, &#39;r&#39;).read())))&quot;
done
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;this gave me the count for &lt;em&gt;every&lt;/em&gt; character. This was a bit more useful, in that there is a fixed universe of possible characters, right? So I could maybe look at the ratio of the alphabet characters a-z to all the special characters. Since English doesn’t use diacritical marks (but this being a paper in Quebec, there will be a certain amount of French marks), special characters, plus umlauts, etc, could be useful. &lt;strong&gt;I have not yet calculated a ratio score&lt;/strong&gt;. I only just thought of it.&lt;/li&gt;
  &lt;li&gt;on DH Slack, I described what I was up to in the ‘DHAnswers’ channel. Finlay McCourt re-wrote the script:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;#!/usr/bin/env python
import collections, pprint, re, sys
with open(sys.argv[1],&#39;r&#39;) as file_in:
    chars = re.sub(&#39;[\s\w!!&quot;#$%&amp;amp;()*+,-./:;&amp;lt;=&amp;gt;?@^_`{|}~\[\]\&#39;\\\]&#39;,&#39;&#39;, file_in.read())
    counts = collections.Counter(chars)
pprint.pprint(counts.most_common())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…which counts the special characters, and puts them into a json-ish format. I called this script &lt;code&gt;bettercount.py&lt;/code&gt; and put a bash wrapper around it: &lt;code&gt;for f in *; do python bettercount.py $f; done&lt;/code&gt;. Thus, in my directory with the txt files, I piped commands together:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./feedfile.sh &amp;gt; output.csv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;…which passes each file to bettercount.py. I opened &lt;code&gt;output.csv&lt;/code&gt; in Sublime Text (which handles find &amp;amp; replace much better than Atom). I delete new lines to get each file and the number and count of special characters, one per line. I know I could have done this in my &lt;code&gt;bettercount.py&lt;/code&gt; script, but &lt;em&gt;shrug&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’m working on a Mac, and I’ll be damned if I can figure out Numbers for working with spreadsheets. I copied my output to a &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1g04mSEYUA11uGnW6QDOyOXOcrYh6DRlLOIvytXHTXd8/edit?usp=sharing&quot;&gt;google spreadsheet&lt;/a&gt;. I added up the number of special characters. &lt;strong&gt;Again, I could calculate a ratio here of numbers of special characters to possible special character types, to normalize things&lt;/strong&gt;. That might be a good idea.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;step-5-visualizing-the-results-how-bad-is-my-ocr&quot;&gt;Step 5: ‘Visualizing’ the results: How bad is my OCR?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;I’m not keen on graphs at the moment. As part of a larger project, I’m trying to make visualization strange again so that the kinds of unconsicous bias that come from received notions of how-to-graph-things don’t get in the way.&lt;/li&gt;
  &lt;li&gt;So I sonified all this with Musicalgorithms.com, &lt;a href=&quot;http://musicalgorithms.org/3.0/index.html&quot;&gt;version 3&lt;/a&gt;.
    &lt;ul&gt;
      &lt;li&gt;take the column of numbers to sonify. Remove line breaks so that all the numbers are on a single line, separated by a single space&lt;/li&gt;
      &lt;li&gt;paste this line into the musicalgorithms csv format:&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;# Of Voices, Text Area Name, Text Area Data
1,morphBox,
,areaPitch1,1140 2 991 [etc]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;hit the ‘load’ button on Musicalgorithms, &lt;strong&gt;paste&lt;/strong&gt; the formatted data into the box. (I say ‘paste’ because loading the csv directly, when you have this many ‘notes’, seems to introduce errors that bork the sonification).&lt;/li&gt;
  &lt;li&gt;I moved directly to ‘play/download’ and accepted all of the default parameter mappings.&lt;/li&gt;
  &lt;li&gt;I placed the resulting .mid file into Garageband to try to make the ‘sonification’ into rather more pleasing music. Well, ‘pleasing’ for a given value of pleasure, I guess.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;the ‘music’ can be heard at &lt;a href=&quot;https://soundcloud.com/shawn-graham-60451318/bad-equity&quot;&gt;soundcloud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;the defaults at musicalgorithms take the first few notes and apply a kind of &lt;em&gt;ritardo&lt;/em&gt; to slow them down, to make a kind of intro.&lt;/li&gt;
  &lt;li&gt;I added the drum beat because part of my larger project is to acknowledge the performative, &lt;em&gt;capta&lt;/em&gt; aspect of all visualization. It’s jarring, and that’s deliberate, because I want the listener to reflect on the performative aspects of all visualizations… that’s a post/paper for another day.&lt;/li&gt;
  &lt;li&gt;You can hear the deep plunks when there are gaps in the record; you can hear the really high notes when a txt file is filled with garbage. The rather narrow range of notes implies that there are certain kinds of special characters that repeat over and over, which is suggestive of the kinds of errors that the OCR is making.&lt;/li&gt;
  &lt;li&gt;Garageband makes a kind of visualization of the music, a player-piano roll-esque side-scroller, showing the values mapped over the 88 tones of the keyboard. This visualization, notwithstanding what I said above, is actually rather interesting:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://pbs.twimg.com/media/CiI9f_oWsAEzwoN.jpg&quot; alt=&quot;garagebandviz&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note how the notes are rather dispersed in the earliest scans (at left, 1883) and become more and more tightly focussed as time spans towards 1914 (at right). That up-and-down tick at the right? My suspicion, yet to be confirmed, is that that corresponds to either a) new printing technology b) new typeface c) the move to Shawville when Shawville began to eclipse Bryson for prominence d) all of the above?&lt;/p&gt;

&lt;h2 id=&quot;what-have-i-learned&quot;&gt;What have I learned?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;dipping into the txt files from 1914, the eye can immediately determine that we have better quality scans. Using the special characters as a proxy for bad OCR &lt;strong&gt;seems&lt;/strong&gt; to be valid. But how can I validate this impression?&lt;/li&gt;
  &lt;li&gt;the patterning of the cloud of special characters &lt;strong&gt;might&lt;/strong&gt; be giving me a way of exploring something of the materiality of printing? It reminds me of Ingrid’s DH MA thesis at Carleton, where she adduced how small errors in reprints of &lt;em&gt;A History of the Pyrates&lt;/em&gt; said more about the culture/physical situation of printers than the world of authors&lt;/li&gt;
  &lt;li&gt;For all my sonification, it’s the visual player-piano roll that seems to be giving me the most useful information&lt;/li&gt;
  &lt;li&gt;That said, the sound itself forces a different kind of attention whilst listening, and the narrowing of tone over time does come across. Or am I just looking for that, now that I’ve seen the player-piano roll? Another ‘auditory hallucination’? see my &lt;a href=&quot;http://programminghistorian.github.io/ph-submissions/lessons/sonification&quot;&gt;Programming Historian tutorial (under-review version)&lt;/a&gt;:
&amp;gt;What’s going on here? If that song was already known to you, you probably heard the actual ‘words’. Yet, no words are present in the song - if the song was not already familiar to you, it sounded like garbled nonsense (see more examples on Andy Baio’s website). This effect is sometimes called an ‘auditory hallucination’. This example shows how in any representation of data we can hear/see what is not, strictly speaking, there. We fill the holes with our own expectations. &lt;br /&gt; Consider the implications for history. If we sonify our data, and begin to hear patterns in the sound, or odd outliers, our cultural expectations about how music works (our memories of similar snippets of music, heard in particular contexts) are going to colour our interpretation. This I would argue is true about all representations of the past, but sonifying is just odd enough to our regular methods that this self-awareness will help us identify or communicate the critical patterns in the (data of the) past.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;to-do-next&quot;&gt;To do next:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;get more txt files&lt;/li&gt;
  &lt;li&gt;re-run the analysis. Do the patterns hold up?&lt;/li&gt;
  &lt;li&gt;what are the special characters doing?&lt;/li&gt;
  &lt;li&gt;use exiftool to consider the metadata&lt;/li&gt;
  &lt;li&gt;how can I make this data haptic?&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 11 May 2016 09:02:00 -0400</pubDate>
        <link>http://smgprojects.github.io/experiment-bad-equity/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/experiment-bad-equity/</guid>
        
        <category>soundbashing</category>
        
        <category>ocr</category>
        
        <category>newspapers</category>
        
        
        <category>Experiment</category>
        
      </item>
    
      <item>
        <title>reilly2015</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#reading-report&quot; id=&quot;markdown-toc-reading-report&quot;&gt;Reading report&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#summary&quot; id=&quot;markdown-toc-summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tabular-representation&quot; id=&quot;markdown-toc-tabular-representation&quot;&gt;Tabular Representation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;&lt;span id=&quot;reilly2015&quot;&gt;Reilly, Paul. “Additive Archaeology: An Alternative Framework For Recontextualising Archaeological Entitites.” &lt;i&gt;Open Archaeology&lt;/i&gt;, 2015.&lt;/span&gt;&lt;/h4&gt;

&lt;p&gt;A copy of this is lodged &lt;a href=&quot;/images/opar-2015-0013.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;style&gt;

table, td, th { border-collapse: collapse; border: 1px solid black }
td { padding: 6px }
th { padding: 6px; background-color: lightgrey}
&lt;/style&gt;

&lt;h2 id=&quot;reading-report&quot;&gt;Reading report&lt;/h2&gt;
&lt;p&gt;for &lt;a href=&quot;http://www.degruyter.com/view/j/opar.2014.1.issue-1/opar-2015-0013/opar-2015-0013.xml&quot;&gt;http://www.degruyter.com/view/j/opar.2014.1.issue-1/opar-2015-0013/opar-2015-0013.xml&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Additive Archaeology: An Alternative Framework for Recontextualising Archaeological Entities&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subject:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Themes:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Literature:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Interesting Bits:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Conclusion1:  I meanthat the refabricated excavation will be both a geometrically and compositionally accurate reiteration. A heuristic rematerialisation through which the curious can explore iteratively, reflexively and extensively the disaggregation and recomposition of archaeological entities encountered through archaeological intervention in such a way as to engender a virtuous, multivalent cycle of recontextualisation, analysis and synthesis. In striving to meet this challenge one can envisage the discipline establishing elements of an exemplary platform for strategic innovation affording the development, and structured introduction, of novel and distinctly archaeological approaches to understanding archaeological entities.&lt;/li&gt;&lt;li&gt;Additive4: he long-term value of this proposal will emerge from the experiences researchers will gain during the mission to refine, or re-engineer, the processes of archaeological field recording so that excavations, contexts and assemblages could be refabricated in&lt;/li&gt;&lt;li&gt;Additive3:   What is to stop archaeologists from recording their excavations so that they could be refabricated in ways, for instance, that are not just synthetically haptic but authentically tactile, or perhaps made with the same material properties and characteristics and therefore also affording acoustic responses and auralisations? From a digital archaeology resource point of view, it would require prodigious amounts of computer processing power and storage, orders of magnitude greater than currently available (depending on the resolution we choose) not to mention the availability of versatile, multi-graded, multi-material fabrication units. &lt;/li&gt;&lt;li&gt;Additive2: his technology challenges archaeologists to rethink how the archaeological record is materialised. By incorporating AMF-like concepts into archaeological recording practice perhaps we can better foster and promote a renewed multi-modal sensorial prominence and increased cognitive depth.  Some will argue that existing procedures are adequate for current (epistemological) needs. However, in a uniquely destructive discipline, are we not ethically obliged to strive constantly for superior recording practices and access to the archaeological record that we simultaneously destroy and create? Christopher Witmore has articulated the value of anticipation, and it is very difficult to disagree with his assertion that “there is absolutely no excuse for not considering how archaeologists, or myriad other interested groups, will engage the material past 10, 50, 100 or more years from now” [37]&lt;/li&gt;&lt;li&gt;Additive1: What is striking about the AMF format is that it encapsulates many of the key descriptive elements found on the typical context and object recording sheets used on a modern archaeological excavation (e.g. Figure 2), but does so in much finer spatio-compositional, that is in both macro-morphological and micro-morphological, detail&lt;/li&gt;&lt;li&gt;simulacra7:  In either case, however, different configurations are discernible depending on where in the matrix of relationships between these things, their context, us, all our apparatus, and theoretical assumptions, the phenomenon is studied. &lt;/li&gt;&lt;li&gt;Simulacra6: f the immaterial orthothetic digital code for the mere husk of an object can give rise to such rich material and discursive intra-actions, imagine the transcendental potency that might be obtained by encoding the substance, including the interstitial structures, compositions and relationships buried beneath the skin of these material things&lt;/li&gt;&lt;li&gt;Simulacra5: Whereas the limits of the physical objects may be clearly defined surfaces, the boundaries of the digital object are drawn by the same file format in which they are encoded, that is the same digital code that marks the content and the voids. Such digital artefacts and assemblages besides being porous are easily networked, replicated, aggregated, augmented, processed or transcoded into other formats [33], and thereby extended&lt;/li&gt;&lt;li&gt;Simulacra4:  Empty moulds or reservoirs full of mortal terror, neither structure, nor artefact, nor deposit, they sit on the cusp of being either (or neither) positive or negative stratigraphic features. Ontologically ambiguous, stratigraphically a collection of sealed contexts, this immaterial assemblage is simultaneously earlier, co-terminus, and later than the layer of volcanic spew.&lt;/li&gt;&lt;li&gt;Simulacra3: ltimately, and perhaps ironically, it is the ‘immaterial digital code’ that emerges as the most stable entity between and betwixt virtual and physical worlds [11, pp.281-283]. Although buried under a deep stratigraphic sequence of software layers, in fact the code actually exists on a physical inorganic substrate. The code can be conceptualised as “a second-order form of materiality” [33, p.122]. Nevertheless, the act of inscription using this multi-sensorial mnemotechnology is indeed orthotheticin nature [34] as it captures the ‘exact’ spatial pose of some material entity or assemblage - from one unique fleeting moment of time - and makes it available, in code, exactly as sampled, theoretically for all time&lt;/li&gt;&lt;li&gt;Simulacra2: Categorisations such as replicas, copies or imitations do not sit comfortably with these newly printed objects which burst free of such procrustean registers to be (re)printed, endlessly, in different materials, at different scales, with enhanced morphological features, with different material properties, in multiple spatio-temporal locales.&lt;/li&gt;&lt;li&gt;Simulacra1: . What is the ontological status of these new printed objects and the code describing them?&lt;/li&gt;&lt;li&gt;EvolvingAdditiveManufacturing: Consider the possibilities of a library of voxel types with archaeologically-defined materials and properties (e.g., compact, light brown, silty clay, with sparse white, coarse, sub-angular, components, etc.)&lt;/li&gt;&lt;li&gt;Disruptingdiscourse1:  Additive manufacturing is disruptive for archaeologists because it poses a number of problems for conventional understandings of materiality [11-12], and especially the so-called archaeological record.  In particular, concepts such as real, virtual, and authentic are becoming increasingly unstable as archaeological artefacts and assemblages are digitalised, reiterated, extended and distributed through time and space as 3D printable entities [1&lt;/li&gt;&lt;li&gt;Materialising8: the material world is, at any given time, an archive of this process of (de)materialization” [3, p.205]&lt;/li&gt;&lt;li&gt;Materialising7: Complimentary processes (called enchainment or coding) cohere to generate recurring associations such as typological similarities or repeated find combinations.&lt;/li&gt;&lt;li&gt;Materialising6: Here, depositional processes (called containment or territorialisation) cohere to assemble, or gather, things in specific places&lt;/li&gt;&lt;li&gt;Materialising5: the practices of the field archaeologist are not so much data collection but interventions, or material interactions, in which tools and procedures are mobilised locally to materialise new entities or artefacts (e.g. drawings, samples, photographs, context sheets, field diaries, finds and reports); it is these new, mobile, dynamic assemblages of autonomous objects that become archives.  &lt;/li&gt;&lt;li&gt;Materialising4: viewing any one facet in isolation can lead to fundamental disconnects or an “interpretive dilemma, in which explanations often hover between vacuity and incommensurability” [3, p.169].&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id=&quot;tabular-representation&quot;&gt;Tabular Representation&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;Observation&lt;/th&gt;&lt;th&gt;Resonances&lt;/th&gt;&lt;th&gt;Crossref&lt;/th&gt;&lt;th&gt;Problems&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;additive 4 right. b/c that would cause us to rethink the ways we break apart / build up archae knowledge&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;additive3 printing out site in material that replicates literal granularity of context description; haptics, sonic, other qualities&lt;/td&gt;&lt;td&gt;Stu Eve&#39;s embodied GIS, phenomenology&lt;/td&gt;&lt;td&gt;JAMT 19 (4) pp. 582-600&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Ethical dimensions of the challenge posed by AMF file format&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Additive1 This is incredibly important. An entire fileformat that captures what we think of as the physical reality of a site?&lt;/td&gt;&lt;td&gt;I wonder what Eric thinks&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra7 &#39;assemblage&#39;, the things assembled, depend on which relationships we think are important&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra6 ... and imagine when vast assemblages of extracted data are made into things...&lt;/td&gt;&lt;td&gt;Soundbashing&lt;/td&gt;&lt;td&gt;Tara&#39;s post photobashing&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra4 on the ontologically complicated voids at Pompeii, from whence are cast moulds of the dead&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra3 woah. of course - code actually eists as a physical thing on a physical device somewhere...&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra2 the contrast between &#39;replica&#39; and &#39;simulacra&#39; is interesting. &lt;/td&gt;&lt;td&gt;perhaps that ties into some of my arguments about what ABM achieve, are for?&lt;/td&gt;&lt;td&gt;JAMT me &amp;amp; scott&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;simulacra1 - critical code studies?&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;evolving1 voxel dfn?&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;disrupting1 Interesting that there is no discussion of &#39;aura&#39; here&lt;/td&gt;&lt;td&gt;problem of fakes?&lt;/td&gt;&lt;td&gt;where&#39;s that damned phd thesis on cultural, economic significance of fakes? On the other machine?&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;materialising8 decisions are made in &#39;real&#39; archives about what is kept, what is left out. &lt;/td&gt;&lt;td&gt;I wonder how far the metaphor of the &#39;archive&#39; can be pushed before it breaks? Before it conceals more than it reveals?&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;materialising7 &#39;enchainment&#39; is a cool word; seems to suggest an element of coercion, perhaps? This must be Lucas&#39; term.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;materialising6 &#39;containment&#39; - who/what does the containing? Depositional processes. &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;materialising5 data are always constructed; the act of &#39;collecting&#39; is also an act of creation. Here, it literally results in the creation of new material culture too.&lt;/td&gt;&lt;td&gt;Drucker&lt;/td&gt;&lt;td&gt;DHQ 2011, 5:1&lt;/td&gt;&lt;td&gt;Problems:&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Materialising4 - quote is from Lucas&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
</description>
        <pubDate>Fri, 06 May 2016 12:55:00 -0400</pubDate>
        <link>http://smgprojects.github.io/reilly2015/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/reilly2015/</guid>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>Tags and Subtags in Hypothesis</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#tags&quot; id=&quot;markdown-toc-tags&quot;&gt;tags&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;tags&quot;&gt;tags&lt;/h1&gt;

&lt;p&gt;When using the &lt;a href=&quot;https://github.com/smgprojects/notebook/tree/master/source/scripts&quot;&gt;tagging script&lt;/a&gt; &lt;code&gt;getannotations.py&lt;/code&gt; the tags in hypothesis have to be structured. The diagram below shows the current structure I am trying to use. See the &lt;a href=&quot;http://smgprojects.github.io/demo-of-reading-report-from-hypothesis-script/&quot; title=&quot;demo of reading report from hypothesis script&quot;&gt;demo output&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/BB_00085.pdf.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 06 May 2016 11:21:00 -0400</pubDate>
        <link>http://smgprojects.github.io/tags-and-subtags-in-hypothesis/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/tags-and-subtags-in-hypothesis/</guid>
        
        <category>workflow</category>
        
        <category>annotations</category>
        
        
        <category>Meta</category>
        
      </item>
    
      <item>
        <title>demo of reading report from hypothesis script</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#script&quot; id=&quot;markdown-toc-script&quot;&gt;script&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#output&quot; id=&quot;markdown-toc-output&quot;&gt;output:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reading-report&quot; id=&quot;markdown-toc-reading-report&quot;&gt;Reading report&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#summary&quot; id=&quot;markdown-toc-summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tabular-representation&quot; id=&quot;markdown-toc-tabular-representation&quot;&gt;Tabular Representation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;script&quot;&gt;script&lt;/h2&gt;
&lt;p&gt;Script is at &lt;a href=&quot;https://gist.github.com/shawngraham/8dddf5b924588184b0568ca98f827b8b&quot;&gt;https://gist.github.com/shawngraham/8dddf5b924588184b0568ca98f827b8b&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I changed it to save as .md; then I copy the html from that file and paste into my open notebook template for a note card. The html that follows below is generated from the script above.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;if you use the script, the tag from lines 82-85 &lt;strong&gt;must&lt;/strong&gt; be used with &lt;code&gt;:1&lt;/code&gt; etc, iterating upwards as you go.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;individual annotations should use the headings in line 105 with colons, in order to appear in the table.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;output&quot;&gt;output:&lt;/h2&gt;

&lt;style&gt;

table, td, th { border-collapse: collapse; border: 1px solid black }
td { padding: 6px }
th { padding: 6px; background-color: lightgrey}
&lt;/style&gt;

&lt;h2 id=&quot;reading-report&quot;&gt;Reading report&lt;/h2&gt;
&lt;p&gt;for &lt;a href=&quot;http://www.degruyter.com/view/j/opar.2014.1.issue-1/opar-2015-0013/opar-2015-0013.xml&quot;&gt;http://www.degruyter.com/view/j/opar.2014.1.issue-1/opar-2015-0013/opar-2015-0013.xml&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Additive Archaeology: An Alternative Framework for Recontextualising Archaeological Entities&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Subject:&lt;/strong&gt; 3: grand disciplinary challenge, 2: real, virtual, and authentic are becoming increasingly unstable, 1: Additive manufacturin&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Themes:&lt;/strong&gt; 1: a radical new generative framework within which to recontextualise and reconsider the nature of archaeological entities specifically within the domain of digital archaeology, 1: avin Lucas’ characterisation of the archaeological record as a product of contending processes of materialisation and dematerialisation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Literature:&lt;/strong&gt; 1: Lucas, G., Understanding the Archaeological Record, Cambridge University Press, Cambridge, 2012.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Interesting Bits:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Materialising the record: the material world is, at any given time, an archive of this process of (de)materialization” [3, p.205]&lt;/li&gt;&lt;li&gt;Materialising the record: Here, depositional processes (called containment or territorialisation) cohere to assemble, or gather, things in specific places&lt;/li&gt;&lt;li&gt;Materialising the record: Complimentary processes (called enchainment or coding) cohere to generate recurring associations such as typological similarities or repeated find combinations.&lt;/li&gt;&lt;li&gt;Materialising the record: the practices of the field archaeologist are not so much data collection but interventions, or material interactions, in which tools and procedures are mobilised locally to materialise new entities or artefacts (e.g. drawings, samples, photographs, context sheets, field diaries, finds and reports); it is these new, mobile, dynamic assemblages of autonomous objects that become archives.  &lt;/li&gt;&lt;li&gt;Materialising the record: he archaeological record as constructed in the present, also known as the archive.&lt;/li&gt;&lt;li&gt;Materialising the record: the first connotation is that of material culture, materiality or artefacts understood in their broadest sense&lt;/li&gt;&lt;li&gt;Materialising the record: next meaning is expressed in terms of how deposits and assemblages come to be, something he labels as “formation theory&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id=&quot;tabular-representation&quot;&gt;Tabular Representation&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;Observation&lt;/th&gt;&lt;th&gt;Resonances&lt;/th&gt;&lt;th&gt;Crossref&lt;/th&gt;&lt;th&gt;Problems&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;decisions are made in &#39;real&#39; archives about what is kept, what is left out. &lt;/td&gt;&lt;td&gt;I wonder how far the metaphor of the &#39;archive&#39; can be pushed before it breaks? Before it conceals more than it reveals?&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&#39;containment&#39; - who/what does the containing? Depositional processes. &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&#39;enchainment&#39; is a cool word; seems to suggest an element of coercion, perhaps? This must be Lucas&#39; term.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;data are always constructed; the act of &#39;collecting&#39; is also an act of creation. Here, it literally results in the creation of new material culture too.&lt;/td&gt;&lt;td&gt;Drucker&lt;/td&gt;&lt;td&gt;[DHQ](http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html)&lt;/td&gt;&lt;td&gt;Problems:&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;archaeological record as archive&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;archaeological record as things themselves&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;archaeological record as the processes of how things come to be&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

</description>
        <pubDate>Thu, 05 May 2016 12:42:00 -0400</pubDate>
        <link>http://smgprojects.github.io/demo-of-reading-report-from-hypothesis-script/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/demo-of-reading-report-from-hypothesis-script/</guid>
        
        <category>script</category>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>Beacons and Programming the City</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#readings&quot; id=&quot;markdown-toc-readings&quot;&gt;Readings&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gear--sdks&quot; id=&quot;markdown-toc-gear--sdks&quot;&gt;Gear &amp;amp; SDKS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;readings&quot;&gt;Readings&lt;/h1&gt;

&lt;p&gt;Williams, Mita. The City As Classroom vs. The City As Advertising Platform &lt;em&gt;Medium&lt;/em&gt; https://medium.com/@copystar/the-city-as-classroom-vs-the-city-as-advertising-platform-c3a356753f67#.xcdr64km0&lt;/p&gt;

&lt;h1 id=&quot;gear--sdks&quot;&gt;Gear &amp;amp; SDKS&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.facebook.com/business/a/facebook-bluetooth-beacons&quot;&gt;https://www.facebook.com/business/a/facebook-bluetooth-beacons&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.google.com/beacons/eddystone#full_support_for_eddystone&quot;&gt;https://developers.google.com/beacons/eddystone#full_support_for_eddystone&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://evothings.com/diy-arduino-beacons/&quot;&gt;https://evothings.com/diy-arduino-beacons/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://store.punchthrough.com/collections/all/products/bean&quot;&gt;http://store.punchthrough.com/collections/all/products/bean&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://librarybox.us/&quot;&gt;http://librarybox.us/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://piratebox.cc/&quot;&gt;https://piratebox.cc/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 03 May 2016 09:42:00 -0400</pubDate>
        <link>http://smgprojects.github.io/beacons-and-programming-the-city/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/beacons-and-programming-the-city/</guid>
        
        <category>designdh</category>
        
        <category>IoT</category>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>lupton2014</title>
        <description>&lt;h4&gt;&lt;span id=&quot;lupton2014digital&quot;&gt;Lupton, Deborah. &lt;i&gt;Digital Sociology&lt;/i&gt;. Routledge, 2014.&lt;/span&gt;&lt;/h4&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#theorising-digital-society---chapter-2&quot; id=&quot;markdown-toc-theorising-digital-society---chapter-2&quot;&gt;theorising digital society - chapter 2&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#digital-technologies-and-data-as-sociomaterial-objects&quot; id=&quot;markdown-toc-digital-technologies-and-data-as-sociomaterial-objects&quot;&gt;Digital Technologies and Data as Sociomaterial Objects&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#prosumption-neoliberalism-and-the-sharing-subject&quot; id=&quot;markdown-toc-prosumption-neoliberalism-and-the-sharing-subject&quot;&gt;Prosumption, Neoliberalism and the Sharing subject&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;introduction&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;p2&lt;/strong&gt;
- cites anthros Daniel Miller and Heather Horst (2012:4) on digital techs starting to become constitutive of ‘self-hood, embodiement, social lie, social relations and social institutions’.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;tech not just part of what makes us human, it also makes our social world&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;digital tecnologies are so pervasive and ubiquitous as to be invisible; claims to the contrary are spoken from ‘a jposition which only serves to highlight the now unobtrusive, taken-for-graneted elements of digitisation.’ [sg: I’d say ‘digitisation’ and ‘digitalization’ are slightly different things, and perhaps Lupton is talking here about the latter?]&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;p3&lt;/strong&gt;
- argues that urban space is now a product of surveillance technologies, whether of people or for movement of private/public vehicles, payment of goods,  etc.
- ‘[combination of private photos, video + state surveillance]’ means that we are increasingly becoming digital data subjects, whether we like it or not, and whether we choose this or not’. &lt;a href=&quot;http://www.peasantmuse.com/2012/06/from-data-self-to-data-serf.html&quot;&gt;makes me think of Jeremey Antley’s stuff on data serfs&lt;/a&gt; though ‘subject’ was meant in a slightly different sense in lupton2014&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p5&lt;/strong&gt;
- “If it is accepted that ‘life is digital’ … I would argue that sociology needs to make the study of digital technologies central to its very remit… to study digital society is to focus on many aspects that have long been central preoccupations of sociologists: selfhood, identity, embodiment, power relations and social inqualities, social networks, social structures, social institutions, and social theory.”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p8&lt;/strong&gt;
- ‘digital data are not just automatically created object of digital technologies. They are the products of human action. Human judgement steps in at each stage of the production of data: in deciding what constitutes data; what data are important to collect and aggregate; how they should be classified and organised into heirarchies; whether they are ‘clean’ or ‘dirty’(needing additional work to use for analysis); and so on”. [SG: AMEN!]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p15-16&lt;/strong&gt;
- outlines 4 aspects that define ‘digital sociology’
  - ‘professional digital practice’
  - ‘analyses of digital technology use’
  - ‘digital data analysis’ (quant, qual)
  - critical digital sociology’ (ie reflexive analysis of dig tech ‘informed by social and cultural theory’)
- [sg interesting that there doesn’t seem to be any notion of ‘deformation’ in all of this. Then again, maybe we don’t want social science (is soc. a social science?) deforming things…]&lt;/p&gt;

&lt;h1 id=&quot;theorising-digital-society---chapter-2&quot;&gt;theorising digital society - chapter 2&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;p21&lt;/strong&gt;
- discussing google, facebook, apple, and amazon, calls them ‘internet empires’ which is an interesting choice of words, especially when we think of #dhpoco and/or things like facebookzero, wikipedia gateway, etc, [see http://motherboard.vice.com/read/wikipedia-zero-facebook-free-basics-angola-pirates-zero-rating(http://motherboard.vice.com/read/wikipedia-zero-facebook-free-basics-angola-pirates-zero-rating)]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p22&lt;/strong&gt;
- ‘each act of communication via digital media has become a valuable entity by being transofrmed into digital data that can be aggregated into massive data sets… these acts of communication have become commoditised’
- ‘where once it was the physical labour of workers that produced surplus value, now the intellectural labour of the masses has monetary value, constituting a new information economy in which thought has become reified, public, and commodified’. cites Smith 2013, Thrift 2005,2006 on this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p23&lt;/strong&gt;
- Discussing Lash 2005, 2006 on flux and flows of information, for Lash 2006, ‘notes that flux is characterised by tensions, struggles for power, whereas pure flow presupposes unrestricted movements.’ [What did Urry sociology beyond societies say on this matter?]
- ‘This distinction between flux and flow of digital networks and data is an important one. It contravenes a dominant representation of digital data as circulating freely… and emphasises that there are difficulites and blockages in the flows inherent to the global information society.’ [SG - struggles over representation, digital heritage, archaeology, gatekeeping of journals etc: flux?]&lt;/p&gt;

&lt;h3 id=&quot;digital-technologies-and-data-as-sociomaterial-objects&quot;&gt;Digital Technologies and Data as Sociomaterial Objects&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;p23&lt;/strong&gt;
- ‘Exponents [of actor-network theory] contend that humans are always imbricated within networks comprised of human and non-human actors and cannot be isolated from these networks’ [sg yep. see Hodder, entangled, Ingold on meshworks, Gosden, pretty much archaeological theory full stop, yes?]
&lt;strong&gt;p24&lt;/strong&gt;
- discusses ‘assemblages’ as denoting an ‘intermingling of the human and non-human in various dynamic ways’. [SG Again, archaeological theory. How come nobody except archaeologists - and even then, a minority - actually reads any archaeological theory? Archaeology very useful in all this digital stuff….]
- ‘…the digital data objects that are brought together through digital technologies … are assemblages of complex interactions of economic, technological, social and cultural logics. Representing digital phenomena as objects serves the purpose of acknolwedging their existence, effects, and power’. [SG makes me think of &lt;a href=&quot;http://platformstudies.com/&quot;&gt;platform studies&lt;/a&gt; as well as linked open data, rdf, ontologies, etc. Wonder what Seb would think.]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p25&lt;/strong&gt;
- ‘software is no longer static: it is constantly responding to inputs from its users and from other networked systems: updating data, recognising location as the user moves around in space, noticing what activities the user is engaging in on her or his device…’ SG which is why games and game studies at the level of representations of how to engage with the world are critically important as the dominate teacher of how to interact with the digital. clumsy phrasing, yes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Whereas many commentators in the popular media governement and business world view digital data as the ultimate forms of truth and accurate knowledge, sociologists and other social theorists have empahsised that these forms of information, like any other type, are scoially created and have a social life, a vitality, of their own. Digital data objects structure our concepts of identity, embodiment, relationships, our choices and preferences and even our access to services or spaces.’ [sg: which is why deformation and breaking are critical?]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;p26&lt;/strong&gt;
- a sociomaterial perspective draws attention to the ‘tangible physicality’ of digital: ‘the maintenance that supports this operation is messy and contingent, often involving pragmatic compromises, negotiations and just-in-time interventions to keep the system working. Geographical, economic social, political and cultural factors - including such basic requirements as a stable electricyt supply and access to a computer network - combine to promote or undermine the workings of digital technologies’. SG: Goes on to point out the problems of e-waste.
- SG: describes the kinds of e-waste. doesn’t mention &lt;em&gt;where&lt;/em&gt; this e-waste turns up - makes me think of those photographs of ship wrecking yards where the workers are all barefoot, etc. ewaste is one place where dh could point a bit more of its focus, colonial ramifications of, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;p27&lt;/strong&gt;
- discusses the ‘materiality’ of digital objects, esp w/ regard to storage [sg: see &lt;a href=&quot;http://newcloudatlas.org/&quot;&gt;new cloud atlas&lt;/a&gt;]
- digital data ‘decay’ due to format change: “analogue materials that are rendered into digital form for archival purposes and then destoryed may therefore be lost if their digital forms can no longer be used” &amp;lt;- cites Gabrys 2011&lt;/p&gt;

&lt;h3 id=&quot;prosumption-neoliberalism-and-the-sharing-subject&quot;&gt;Prosumption, Neoliberalism and the Sharing subject&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;cf also &lt;a href=&quot;https://via.hypothes.is/https://lareviewofbooks.org/article/neoliberal-tools-archives-political-history-digital-humanities/&quot;&gt;neoliberal tools&lt;/a&gt; &amp;amp; &lt;a href=&quot;http://thehyperlab.ca/the-scandal-of-digital-humanities/&quot;&gt;Brian’s response&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;pg27&lt;/strong&gt; -notes the creative act of interacting with digital techs - makes a kind of ‘prosumer’ (tho discusses that notion &amp;amp; defines it earlier pgs 10-11, under general description of web2.0) - ‘serve a neoliberal [continues to pg28]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;pg28&lt;/strong&gt;
- “political mode of governance.” Defines neoliberalism via its ‘main tenets’, idea of the individual who has responsibility for their own situation; ‘individuals are expected and encouraged to be self-reflexive, or to view their lives as projects that require entrepreneurial investment of time and energy.’ &amp;lt;- cf with &lt;a href=&quot;https://ekansa-pubs.github.io/click-here-to-save-archaeology/&quot;&gt;Kansa, click here to save archaeology&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;also connects with &lt;a href=&quot;http://liu.english.ucsb.edu/the-laws-of-cool-knowledge-work-and-the-culture-of-information-catalogue-copy-and-table-of-contents/&quot;&gt;laws of cool?&lt;/a&gt;? Lupton goes on to tie ‘prosumption’ to Foucault 1988 &lt;a href=&quot;http://foucault.info/doc/documents/foucault-technologiesofself-en-html&quot;&gt;technologies of the self&lt;/a&gt; “the practices of selfhood that make up human actors: those activities that are directed at self-care or self-improvement.” -&amp;gt; a type of social labour.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;pg29&lt;/strong&gt;
- social media as a kind of confessional, a way of reproducing social norms &amp;amp; expectations [sg social shaming? templated selves? dinah boyd maybe?]&lt;/p&gt;
</description>
        <pubDate>Mon, 02 May 2016 11:39:00 -0400</pubDate>
        <link>http://smgprojects.github.io/lupton2014/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/lupton2014/</guid>
        
        <category>sociology</category>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>Web Annotations</title>
        <description>
&lt;p&gt;I use &lt;a href=&quot;http://hypothes.is&quot;&gt;Hypothes.is&lt;/a&gt; around the web to annotate some of the things I read. Or at least, I’m trying. This page represents an attempt at bringing those annotations into this notebook. This may or may not be a useful exercise. My thanks to &lt;a href=&quot;https://twitter.com/ryanfb/status/727145602119774209&quot;&gt;Ryan Baumann&lt;/a&gt; for some suggestions on how to do this.&lt;/p&gt;

&lt;!-- start feedwind code --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;document.write(&#39;\x3Cscript type=&quot;text/javascript&quot; src=&quot;&#39; + (&#39;https:&#39; == document.location.protocol ? &#39;https://&#39; : &#39;http://&#39;) + &#39;feed.mikle.com/js/rssmikle.js&quot;&gt;\x3C/script&gt;&#39;);&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;&gt;(function() {var params = {rssmikle_url: &quot;https://hypothes.is/stream.atom?user=shawn.graham&quot;,rssmikle_frame_width: &quot;600&quot;,rssmikle_frame_height: &quot;400&quot;,frame_height_by_article: &quot;0&quot;,rssmikle_target: &quot;_blank&quot;,rssmikle_font: &quot;Arial, Helvetica, sans-serif&quot;,rssmikle_font_size: &quot;12&quot;,rssmikle_border: &quot;off&quot;,responsive: &quot;off&quot;,rssmikle_css_url: &quot;&quot;,text_align: &quot;left&quot;,text_align2: &quot;left&quot;,corner: &quot;off&quot;,scrollbar: &quot;on&quot;,autoscroll: &quot;off&quot;,scrolldirection: &quot;down&quot;,scrollstep: &quot;3&quot;,mcspeed: &quot;20&quot;,sort: &quot;Off&quot;,rssmikle_title: &quot;on&quot;,rssmikle_title_sentence: &quot;My annotations from across the web using hypothes.is&quot;,rssmikle_title_link: &quot;&quot;,rssmikle_title_bgcolor: &quot;#0066FF&quot;,rssmikle_title_color: &quot;#FFFFFF&quot;,rssmikle_title_bgimage: &quot;&quot;,rssmikle_item_bgcolor: &quot;#FFFFFF&quot;,rssmikle_item_bgimage: &quot;&quot;,rssmikle_item_title_length: &quot;55&quot;,rssmikle_item_title_color: &quot;#0066FF&quot;,rssmikle_item_border_bottom: &quot;on&quot;,rssmikle_item_description: &quot;on&quot;,item_link: &quot;off&quot;,rssmikle_item_description_length: &quot;150&quot;,rssmikle_item_description_color: &quot;#666666&quot;,rssmikle_item_date: &quot;gl1&quot;,rssmikle_timezone: &quot;Etc/GMT&quot;,datetime_format: &quot;%b %e, %Y %l:%M %p&quot;,item_description_style: &quot;text&quot;,item_thumbnail: &quot;full&quot;,item_thumbnail_selection: &quot;auto&quot;,article_num: &quot;15&quot;,rssmikle_item_podcast: &quot;off&quot;,keyword_inc: &quot;&quot;,keyword_exc: &quot;&quot;};feedwind_show_widget_iframe(params);})();&lt;/script&gt;
&lt;div style=&quot;font-size:10px; text-align:center; width:600px;&quot;&gt;&lt;a href=&quot;http://feed.mikle.com/&quot; target=&quot;_blank&quot; style=&quot;color:#CCCCCC;&quot;&gt;RSS Feed Widget&lt;/a&gt;&lt;!--Please display the above link in your web page according to Terms of Service.--&gt;&lt;/div&gt;
&lt;!-- end feedwind code --&gt;
&lt;!--  end  feedwind code --&gt;
</description>
        <pubDate>Mon, 02 May 2016 10:49:00 -0400</pubDate>
        <link>http://smgprojects.github.io/web-annotations/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/web-annotations/</guid>
        
        <category>annotations</category>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>Items to Read concerning Glitch</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#blog-posts&quot; id=&quot;markdown-toc-blog-posts&quot;&gt;Blog Posts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#essays&quot; id=&quot;markdown-toc-essays&quot;&gt;Essays&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#books&quot; id=&quot;markdown-toc-books&quot;&gt;Books&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#museums&quot; id=&quot;markdown-toc-museums&quot;&gt;Museums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kramer:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For Tanner, as for all my students, deformance and glitching helped them look and listen more closely. Their attention bore sophisticated interpretive fruit, both about the folk revival itself and the larger methods by which we perceive and make sense of artifacts and evidence to produce historical meaning. These tactics make use of the strange material qualities of digital code, of the interplay between machine readable and the human readable, of the ability to “mess” with artifacts as they converge in the digital medium. For some historians, deformance and glitching might seem quite disconcerting, at their worst resembling something like Stalin airbrushing a Soviet official out of a photograph after sending him to the gulag. But if handled smartly as a new method, they can render history more revealing, more accurate, more illuminating. &lt;br /&gt;&lt;br /&gt; We glitch for glimmers of truth lurking in the data. We deform to deliver how history develops at the surface as well as below it, above it, of it, beyond it. We distort for discovery—the past’s endless arrangements and rearrangements of code and meaning, significance and power, assembling in a process that always breaks down, degrading into signals that were once disorganized yet, as we turn back to them, build up again into new clues, new songs, new messages, new stories.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;blog-posts&quot;&gt;Blog Posts&lt;/h1&gt;

&lt;p&gt;Kramer, Michael. &lt;a href=&quot;http://www.michaeljkramer.net/cr/distorting-history-to-make-it-more-accurate/&quot;&gt;Distorting History to Make it More Accurate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blevins, Cameron. &lt;a href=&quot;http://www.cameronblevins.org/posts/the-new-wave-of-review/&quot;&gt;The New Wave of Review&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Owens, Trevor. &lt;a href=&quot;https://blogs.loc.gov/digitalpreservation/2012/11/glitching-files-for-understanding-avoiding-screen-essentialism-in-three-easy-steps/&quot;&gt;Glitching Files for Understanding: Avoiding Screen Essentialism in Three Easy Steps&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sample, Mark. &lt;a href=&quot;http://www.samplereality.com/2012/05/02/notes-towards-a-deformed-humanities/&quot;&gt;Notes towards a deformed humanities&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Turkel, Bill. &lt;a href=&quot;https://williamjturkel.net/teaching/digital-humanities-1011b-programming-winter-2014-assignment-4-visualization-sonification/&quot;&gt;Sonification exercise&lt;/a&gt; &lt;strong&gt;what platform is Bill using?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Schedel, Margaret. &lt;a href=&quot;https://soundstudiesblog.com/2014/10/09/sounds-of-science-the-mystique-of-sonification/&quot;&gt;Sounds of Science: the mystique of sonification&lt;/a&gt; … has a section on the deep history of sonification (Galileo, Hooke, etc) &lt;strong&gt;nb&lt;/strong&gt; check out here &lt;a href=&quot;http://schedel.net/publications/&quot;&gt;publications&lt;/a&gt;; website tagline ‘ferociously interactive media’. I like that.&lt;/p&gt;

&lt;h1 id=&quot;essays&quot;&gt;Essays&lt;/h1&gt;

&lt;p&gt;Samuels, Lisa &lt;a href=&quot;If Meaning, Shaped Reading, and Leslie Scalapino&#39;s Way&quot;&gt;If Meaning, Shaped Reading, and Leslie Scalapino’s Way&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;McGann and Samuels, &lt;a href=&quot;http://www2.iath.virginia.edu/jjm2f/old/deform.html&quot;&gt;Deformance and Interpretation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://plato.stanford.edu/entries/models-science/&quot;&gt;Models in Science&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Palmer (née Reiser) M. Jones O. (2014), “On breathing and geography: explorations of data sonifications of timespace processes with illustrating examples from a tidally dynamic landscape (Severn Estuary, UK)”; Environment and Planning A, 46, (1), pp 222 – 240. &lt;a href=&quot;https://ecologicalhumanities.files.wordpress.com/2015/10/riser-jones-sonification.pdf&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;books&quot;&gt;Books&lt;/h1&gt;

&lt;p&gt;Ramsay, Stephen &lt;em&gt;Reading Machines&lt;/em&gt; &lt;strong&gt;who did I lend my copy to? Damn!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kirschenbaum, Matthew. &lt;em&gt;Mechanisms: New Media and the Forensic Imagination.&lt;/em&gt; Cambridge Mass.: MIT Press, 2008.&lt;/p&gt;

&lt;p&gt;Stephan Sinclair &amp;amp; Geoffrey Rockwell &lt;a href=&quot;https://mitpress.mit.edu/books/hermeneutica&quot;&gt;&lt;em&gt;Hermeneutica&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Montfort, Nick &lt;a href=&quot;https://mitpress.mit.edu/exploratory&quot;&gt;Exploratory Programming for the Arts and Humanities&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Salter, Chris. &lt;a href=&quot;https://mitpress.mit.edu/books/entangled&quot;&gt;Entangled: Technology and the Transformation of Performance&lt;/a&gt; also in our &lt;a href=&quot;http://catalogue.library.carleton.ca/record=b2819069&quot;&gt;library&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;museums&quot;&gt;Museums&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mhs.ox.ac.uk/&quot;&gt;Museum of the History of Science&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mathematics artefacts data set, xml, &lt;a href=&quot;http://source.techno-science.ca/datasets-donn%C3%A9es/artifacts-artefacts/groups-groupes/mathematics-mathematiques.xml&quot;&gt;Canadian Science and Technology Museum&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Horology artefacts data set, xml, &lt;a href=&quot;http://source.techno-science.ca/datasets-donnees/artifacts-artefacts/groups-groupes/Horology-en.xml&quot;&gt;Canadian Science and Technology Museum&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Physics artefacts data set, xml, &lt;a href=&quot;http://source.techno-science.ca/datasets-donn%C3%A9es/artifacts-artefacts/groups-groupes/physics-physique.xml&quot;&gt;Canadian Science and Technology Museum&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Apr 2016 08:53:00 -0400</pubDate>
        <link>http://smgprojects.github.io/items-to-read-re-glitch/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/items-to-read-re-glitch/</guid>
        
        <category>soundbashing</category>
        
        <category>to read</category>
        
        <category>deformation</category>
        
        <category>glitch</category>
        
        <category>aesthetics</category>
        
        <category>visualization</category>
        
        
        <category>Readings</category>
        
      </item>
    
      <item>
        <title>Imageplot and Opencontext</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#get-data-out-of-open-context&quot; id=&quot;markdown-toc-get-data-out-of-open-context&quot;&gt;Get data out of Open Context&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#analyze-images-with-imageplot&quot; id=&quot;markdown-toc-analyze-images-with-imageplot&quot;&gt;Analyze images with imageplot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;get-data-out-of-open-context&quot;&gt;Get data out of Open Context&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Eric on how to get stuff out of OpenContext:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/ekansa/status/720706858093137920&quot;&gt;https://twitter.com/ekansa/status/720706858093137920&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/ekansa/status/720827996915900416&quot;&gt;https://twitter.com/ekansa/status/720827996915900416&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://opencontext.org/media-search/Turkey.json?proj=22-kenan-tepe&amp;amp;prop=22-image-type---22-field-photo&amp;amp;response=uri-meta
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;note the &lt;code&gt;.json?&lt;/code&gt; location. Copied the results into Excel &amp;amp; filtered by thumbnail. It was just easier.&lt;/li&gt;
  &lt;li&gt;put the URLs into a text file&lt;/li&gt;
  &lt;li&gt;used wget: &lt;code&gt;wget -r --no-parent -w 2 --limit-rate=10k -i input.txt -nH -nd -np&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;this puts the images into a single folder, rather than replicating opencontext’s deep folders&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;analyze-images-with-imageplot&quot;&gt;Analyze images with imageplot&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;in imageplot, open imagemeasure.txt from the extras folder, run it.&lt;/li&gt;
  &lt;li&gt;in imageplot, open imageplot.txt and run that.&lt;/li&gt;
  &lt;li&gt;for 3d viz of hue, saturation, brightness, see Joel’s post.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://pbs.twimg.com/media/CgFTo6yUUAAjsaR.jpg&quot; alt=&quot;img&quot; /&gt; &lt;a href=&quot;https://twitter.com/electricarchaeo/status/720949378526113792&quot;&gt;https://twitter.com/electricarchaeo/status/720949378526113792&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pbs.twimg.com/media/CgFWG0mVIAAUA19.jpg&quot; alt=&quot;img&quot; /&gt; &lt;a href=&quot;https://twitter.com/electricarchaeo/status/720952091364233221&quot;&gt;https://twitter.com/electricarchaeo/status/720952091364233221&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Apr 2016 11:47:00 -0400</pubDate>
        <link>http://smgprojects.github.io/imageplot-opencontext/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/imageplot-opencontext/</guid>
        
        <category>archaeology</category>
        
        <category>how-to</category>
        
        <category>images</category>
        
        
        <category>Meta</category>
        
      </item>
    
      <item>
        <title>a test of pdf</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#boogie-board-syncing&quot; id=&quot;markdown-toc-boogie-board-syncing&quot;&gt;Boogie Board syncing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;boogie-board-syncing&quot;&gt;Boogie Board syncing&lt;/h1&gt;

&lt;p&gt;I was given a &lt;a href=&quot;https://myboogieboard.com/ewriters/sync&quot;&gt;boogie board sync&lt;/a&gt;. It’s an interesting little piece of kit, especially if you’re like me you find yourself scribbling notes and reminders and so on onto available pieces of paper. It saves your scrawls as pdf, which then sync via bluetooth onto your machine (it does lots of other things too). There is an app for your phone which does all this, and evernote is also a possible destination.&lt;/p&gt;

&lt;p&gt;I use a simple command to convert the pdfs to pngs to put into my notebook.
&lt;code&gt;
for i in *.pdf; do sips -s format png $i --out $i.png;done
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The result:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/test.pdf.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Apr 2016 19:29:00 -0400</pubDate>
        <link>http://smgprojects.github.io/a-test-of-pdf/</link>
        <guid isPermaLink="true">http://smgprojects.github.io/a-test-of-pdf/</guid>
        
        <category>workflow</category>
        
        <category>notebook</category>
        
        
        <category>Meta</category>
        
      </item>
    
  </channel>
</rss>
